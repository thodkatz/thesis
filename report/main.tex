% !TEX program = xelatex

\documentclass[12pt, a4paper]{article}

\usepackage{fontspec}
\setmainfont[Ligatures=TeX]{Linux Libertine O}
\usepackage[left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm]{geometry}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{dirtytalk}
\usepackage{bookmark}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{float}
\usepackage{siunitx}
\usepackage{color}
\usepackage{indentfirst}

\graphicspath{{assets/}}

\sloppy


\begin{document}

\include{cover}

% \title{Τίτλος διπλωματικής}
% \author{Όνομα Επίθετο \\
% \href{mailto:empty@auth.gr}{empty@auth.gr}}
% \maketitle

{
\renewcommand*\contentsname{Περιεχόμενα}
\hypersetup{linkcolor=black}
\tableofcontents
}

\thispagestyle{empty}

\clearpage

\section{Abstract}

With the recent advancements in single-cell technology and the large scale perturbation datasets, the field of perturbation modeling  has created an opportunity for a wide variety of computational methods to be leveraged to harness its potential. Multi-task learning is one of the methods that has been left unexplored in this field. In this study we aim to bridge this gap unraveling the potential of multi-task learning in single-cell perturbation modeling.


\section{Introduction}    

The complexity of biological systems have imposed a challenge to capture the underlying mechanisms of cellular heterogeneity. Deciphering the effect of external stimuli (perturbation) at the cellular level, a field referred to as perturbation modeling \cite{jiMachineLearningPerturbational2021}, 
%has a significant impact
plays a crucial role
in biomedicine and drug discovery. With the recent surge of data 
generation, machine learning methods aim to understand the effect of perturbations and to extrapolate on unseen events.

An overview of the models on perturbation modeling can be found on this study \cite{gavriilidisMinireviewPerturbationModelling2024}. One of the main objectives is the out-of-distribution detection, which is the focal point of our study. The task is about predicting the perturbation response of the omics signature of cells with a specific cell type, while having observed the perturbation response of other cell types.

UnitedNet \cite{tangExplainableMultitaskLearning2023} is a multi-task framework that has shown its potential in multi-omics tasks such as cross modal prediction and cell type classification. We aim to extend this approach to perturbation modeling.

\section{Current single-cell perturbation modeling methods}

In the literature body, there are several approaches for predicting single-cell perturbation responses. To compare our multi-task method, we have chosen the models of scGen \cite{lotfollahiScGenPredictsSinglecell2019}, scPreGAN \cite{weiScPreGANDeepGenerative2022}, scButterfly \cite{caoScButterflyVersatileSinglecell2024}, and scVIDR \cite{kanaGenerativeModelingSinglecell2023}.

scGen projects the gene expression profile to a probabilistic latent space with a VAE. Then the perturbation effect is modeled with a vector that represents the difference between the control and perturbed gene expression projections in the latent space.

scVIDR builds upon scGen, complementing the architecture with cell type specific knowledge. It can predict the response of multiple chemical perturbations on a dose-dependent use case. scVIDR is one of the instances that is leveraging the data of multiple perturbations to improve the predictions, based on a multi-task approach. 

scPreGAN is based on a GAN and autoencoder setup. The study aims to decouple the perturbation effect from the latent space, and to apply it to the decoder stage.
%This approach could be explored in a multi-task multi-head architecture, where each head will be responsible for a specific perturbationm given a perturbed decoupled latent space. 

scButterfly, although hasn't not been primarily designed for perturbation modeling, its cross modal architecture with dual aligned VAEs can also be used for perturbation objectives. Instead of cross predicting one omic from another one, the perturbed and control gene expressions can be considered as modalities.


\section{Method}

Multi-task learning is a machine learning paradigm and its core idea is that training a model to solve multiple tasks can be more effective than training separate models for each specific task \cite{zhangSurveyMultiTaskLearning2021}. A joint architecture that shares knowledge between the tasks can capture underlying dynamics leading to an enhanced generalization performance.
The relationship of the tasks determines the positive or negative transfer to each other and the overall effectiveness of the paradigm.

Defining as a task the prediction of the gene expression given a perturbation, we will explore designing a model that can predict gene expressions given multiple perturbations and its performance compared to single perturbation approaches.

One of the key problems of deep learning methods is the data demand. Another benefit of multi-task learning is the combination of data from multiple sources of informations, especially in perturbation modeling where the data is limited for a specific number of perturbations. 

To integrate the tasks, we have explored the application of feature-wise transformations \cite{dumoulin2018feature-wise}. For this kind of transformation, we have:

\[ \text{FiLM(x)} = \gamma (z) \odot x + \beta (z) \]

, where $\gamma$, and $\beta$ are learnable parameters generated by a network that represent a condition, $z$ is the condition, such as a vector that indicates the task, and $x$ is the input.

This particular technique is referred to as conditional affine transformation (a combination of multiplicative and additive conditioning) that shifts and scales the input element-wise. It is efficient in terms of scaling and parameters compared to multi-head architectures, where each task has its dedicated network to generate the output of the task.


\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{film_layers.png}
    \caption{Illustration of the feature-wise transformation \cite{dumoulin2018feature-wise}}
    \label{fig:film}
\end{figure}

In our approach, we have attempted to decouple the perturbation effect, creating a perturbation free latent space, while taking control of the perturbation response with the conditioning vector. Thus, our architecture is based on an autoencoder, and the conditioning of the task, which in our case is the type of perturbation, will be delegated via FiLM layers fused in the decoder (\verb|MultiTaskAutoencoder|). The $\gamma$ and $\beta$ are designed to be different for each fusion.
% add a diagram here
We have experimented with a few variations of this, keeping the architecture of the decoder with the inclusion of film layers consistent. Thus, we have the following models:

\begin{itemize}
    \item The \verb|NultiTakAae| is based on an adversarial autoencoder. The discriminator aims to differentiate between control and perturbed gene expressions, and the encoder is trained to fool the discriminator.
    \item The \verb|MultiTaskAaeGaussian| is based on an adversarial autoencoder, that aims to create a latent space that follows the gaussian distribution. The discriminator aims to differentiate between samples of the gene expressions and the gaussian distribution.
    \item add the rest
\end{itemize}


\section{Evaluation}

To evaluate the models, we have used the count of DEGs, along with the $R^2$ of all the DEGs and the top 100 most variable ones. To complement the evaluation, based on scPerturb, we have calculated a set of five distance metrics, to capture the wholeness of the differences between the expected and predicted perturbed gene expressions.

We have tested the models on two datasets, one where human peripheral blood mononuclear cells have been stimulated by IFN-b interferon, and a multi-perturbation dataset, where liver cells have been stimulated by multiple doses of tetrachlorodibenzo-p-dioxin (TCDD) in vivo.

Regarding the single perturbation response models, the scGen, scButterfly, scPreGAN, in the multi-perturbation dataset of ten dosages, we have trained a dedicated model for each dosage.

To address the randomness of the models, we have performed the experiments three times, with three different seeds 1, 2, 19193, and the metrics have been averaged across experiments.


\section{Results}

\subsection{Knowledge transfer}

which tasks and why they are important?

\subsection{TODO}

\begin{itemize}
    \item batch effect
    \item interpretability
    \item explainability
    \item integration with multiple omics
\end{itemize}

\section{Conclusions}

\section{Future work}


\include{chapter1}

\appendix
\include{acronyms}


\bibliographystyle{plain}
\bibliography{references.bib}

\end{document}