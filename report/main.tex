% !TEX program = xelatex

\documentclass[12pt, a4paper]{article}

\usepackage{fontspec}
\setmainfont[Ligatures=TeX]{Linux Libertine O}
\usepackage[left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm]{geometry}

\usepackage{amsmath,amsfonts,amssymb}


\usepackage{dirtytalk}
\usepackage{bookmark}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{float}
\usepackage{siunitx}
\usepackage{color}
\usepackage{indentfirst}
\usepackage{cleveref}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{wrapfig}

\usepackage[acronym]{glossaries}
\makeglossaries

\newcommand{\crefwithname}[1]{\cref{#1}: \nameref{#1}}

\graphicspath{{assets/}}

\sloppy


\begin{document}

\include{cover}

% \title{Τίτλος διπλωματικής}
% \author{Όνομα Επίθετο \\
% \href{mailto:empty@auth.gr}{empty@auth.gr}}
% \maketitle


% \begin{center}
% \textbf{\Large Acknowledgements}
% \end{center}


% \clearpage


{
\renewcommand*\contentsname{Contents}
\hypersetup{linkcolor=black}
\tableofcontents
}

\thispagestyle{empty}

\clearpage
\addcontentsline{toc}{subsection}{List of Figures}
\listoffigures

\clearpage
\addcontentsline{toc}{subsection}{List of Tables}
\listoftables

\clearpage
\addcontentsline{toc}{subsection}{Acronyms}
\include{acronyms}
\printglossary[type=\acronymtype, title=Acronyms]

\clearpage
\addcontentsline{toc}{subsection}{Abstract}
\begin{center}
\textbf{\Large Abstract}
\end{center}

Advanced single-cell technologies have provided new insights on cellular responses to perturbations, with significant potential for translational medicine. However, the inherent complexity of biological systems and the technical limitations of the experimental protocols present challenges for many proposed computational methods to algorithmically capture the perturbation mechanisms. Multi-task learning is one of the methods that have been left unexplored in this field. In this study, we aim to bridge this gap by unraveling its potential in single-cell perturbation modeling. We have developed a multi-task autoencoder architecture that predicts perturbed single-cell transcriptomic profiles for multiple perturbations achieving state-of-the-art performance while exhibiting greater scalability and efficiency compared to existing methods.

\clearpage


% I have mentioned that scvidr is a multi-task model. Thus, maybe I have to rephrase it since there were some attempts but not fully dedicated to explore the multi-task as a learning paradigm per se.

\section{Introduction}

% what is single-cell, what used to be the old bulk data that didn't allow fine grained high dimensional data

The advent of single-cell technologies has enabled the study of the biological heterogeneity at the cellular resolution, opening new avenues for understanding the cellular mechanisms and their responses to perturbations.
However, the perturbation space is vast, and experimentally exploring combinations would be infeasible and costly \cite{heumos2023best, kana2023generative}. This has motivated the development of computational methods to model this space, enabling extrapolation to unseen scenarios through in silico experimentation. The field of deciphering and predicting the effects of external stimuli (gene knockouts, drug dosages, temperature changes, etc.) is referred to as perturbation modeling, and it plays a crucial role in disease mechanism discovery and therapeutic target identification \cite{jiMachineLearningPerturbational2021}.

% intro to the tasks

% I should mention the rest of the tasks

%One of the main objectives of perturbation modeling is \gls{ood} \cite{gavriilidisMinireviewPerturbationModelling2024}, which is the focal point of our study. The task is about predicting the perturbation response of the omics signature of cells with a specific cell type, while having observed the perturbation response of other cell types.

% dataset limitations

Datasets used for perturbation modelling are often highly noisy and sparse due to the inherent limitations of single-cell technologies. For example, dropout events are likely to occur, leading to many zeros in the expression profiles as a failure of detecting lower expression levels. The data is also high-dimensional, typically consisting of thousands of cells profiled across hundreds or thousands of features (e.g., gene expression levels in transcriptomics), which enables fine-grained analysis of cellular responses \cite{jiMachineLearningPerturbational2021}. The perturbation response itself is non-linear and complex, depending not only on the nature of the perturbation but also on the cellular context, including cell type, microenvironment, genetic background, and temporal dynamics \cite{gavriilidisMinireviewPerturbationModelling2024}.

Machine learning methods, particularly deep learning, have shown promise in addressing this complexity by leveraging their generative capacity, made possible by the recent surge in high-throughput single-cell data \cite{gavriilidisMinireviewPerturbationModelling2024}.
More specifically there is a growing trend toward leveraging \gls{llm} in the field. A recent survey by Szalata et al. \cite{szalata2024transformers} highlights this as a promising yet still immature research direction. Key challenges include the lack of standardized evaluation frameworks, model instabilities, insufficiently diverse datasets, and the absence of sequential structure analogous to positional embeddings in natural language processing.
In contrast, autoencoder architectures and their variants have already demonstrated strong performance outperforming transformers \cite{szalata2024transformers}, while offering notable advantages in terms of resource efficiency and reduced computational complexity.


Based on the core deep learning concept of manifold hypothesis, autoencoder architectures aim to learn a low-dimensional representation of the data, capturing the underlying structure of the perturbation response. This is achieved by the encoder-decoder architecture, where the encoder compresses the input data into a lower-dimensional space, while the decoder attempts to reconstruct the original input. This compression can yield biologically meaningful features, resulting in a more interpretable and efficient representation of the data, which can be useful for downstream tasks such as out-of-distribution detection \cite{gavriilidisMinireviewPerturbationModelling2024}.


However, the non-linearity of deep learning models presents another challenge in balancing predictive accuracy with interpretability \cite{kana2023generative}. This trade-off remains a key milestone in the field, and many recent efforts have aimed to address it through causal machine learning approaches such as the GRouNdGAN, sVAE+, and graphVCI \cite{gavriilidisMinireviewPerturbationModelling2024}. Other interpretable approaches include the usage of SHAP values by UnitedNet \cite{tangExplainableMultitaskLearning2023}, integrative gradients by PerturbNet \cite{yuPerturbNetPredictsSinglecell2022},  and the approximation of the function of the uninterpretable non-linear decoder with sparse ridge regression as demonstrated by scVIDR \cite{kanaGenerativeModelingSinglecell2023}.

Additional limitations in the data space, such as batch effects and confounding covariates, also hinder prediction accuracy. To mitigate these issues and improve generalization, recent studies have focused on integrative single-cell omics approaches, including spatial data integration. The target is to learn a low-dimensional representation that disentangles the core biological context while removing technical variations.

% motivation that multi-task has been used in single cell tasks but not in perturbation modeling

%UnitedNet \cite{tangExplainableMultitaskLearning2023} is an explainable framework based on an autoencoder architecture that have addressed the aforementioned limitations while showing  the potential of multi-task learning in multi-omics tasks such as cross modal prediction and cell type classification. We aim to extend this approach to perturbation modeling.

\subsection{Multi-task learning}
\label{sec:mlt}

\gls{mlt} is a machine learning paradigm in which a single model is trained to perform multiple related tasks simultaneously. The central idea is that by sharing representations across tasks, the model can generalize better than if each task were learned in isolation. This approach is inspired by human learning and cognition, where analogy plays a central role in transferring knowledge across domains \cite{hofstadter2001analogy, zhangSurveyMultiTaskLearning2021}. From a machine learning perspective, we can view it as a form of inductive bias. It directs the model to prefer the hypothesis that explains more than one tasks, similarly with L1 regularization that leads to a preference for sparse solutions \cite{ruderOverviewMultiTaskLearning2017}. The degree of benefit depends on the relationship between tasks. If tasks are poorly related, negative transfer may occur, where learning one task harms performance on another \cite{standleyWhichTasksShould2020}. Therefore, understanding task relationships and designing appropriate shared architectures are crucial to the success of \gls{mlt}.

%One of the key problems of deep learning methods is the data demand. Another benefit of multi-task learning is the combination of data from multiple sources of information, especially in perturbation modeling where the data is limited for a specific number of perturbations. 

One of the early-stage motives of \gls{mlt} is the implicit data augmentation by combining the sources of information from multiple tasks to alleviate the data scarcity problem. This is particularly relevant in single-cell multi-omics protocols \cite{caoScButterflyVersatileSinglecell2024}, where the data is often limited due to the complexity and cost of the experiment protocols. This is also beneficial to single-cell single modality datasets, where the data is limited for a specific number of perturbations.

Other advantages of \gls{mlt} include the prevention of overfitting while mitigating the data-dependent noise of each task. Noisy data can obscure the underlying patterns, making it difficult for the model to learn meaningful representations. Combining data from multiple tasks provides additional evidence, so the model can distinguish relevant features from irrelevant ones, leading to more robust features \cite{ruderOverviewMultiTaskLearning2017}. This is particularly important in single-cell perturbation modeling, where the data is often noisy and sparse due to dropout events and other technical limitations. 

Regarding the architecture choise of \gls{mlt}, we need to consider how to process the interplay of the tasks, a concept referred as conditioning \cite{dumoulin2018feature-wise}. In the context of deep learning, the most prominent approaches are the hard and soft parameter sharing. In hard parameter sharing, the model shares a common set of parameters across all tasks, while keeping a dedicated head for each one (\cref{fig:hard}). It is the most common approach and often preferred when tasks are closely related, as it allows for more efficient learning, reducing the risk of overfitting. In soft parameter sharing, each task has its own set of parameters, but they are encouraged to be similar through regularization (\cref{fig:soft}). It is more suitable for tasks that are less related, as it allows for more flexibility in task-specific representations, while being less prone to negative transfer \cite{ruderOverviewMultiTaskLearning2017}.

\begin{figure}[h!]
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=.6\textwidth]{hard.png}
        \caption{Hard parameter sharing}
        \label{fig:hard}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{soft.png}
        \caption{Soft parameter sharing}
        \label{fig:soft}
    \end{subfigure}
    \caption{Task conditioning \cite{ruderOverviewMultiTaskLearning2017}}
    \label{}
\end{figure}

Another approach of conditioning the tasks is the family of feature-wise transformations. In this approach, we can have three different transformations, a) the concatenation, b) the addition, and c) the multiplication. These transformations can be applied in a layer-wise manner, allowing for more flexibility in how tasks are integrated into the model. They can be incorporated either at the initial input of the architecture or at a later stage of the generation process. For the concatenation, given a representation of a task, $z$, (e.g. one-hot encoded), the input of a layer is concatenated with $z$, and the output is their linear transformation. For the addition and the multiplication, the conditioning representation is linearly transformed and then added and multiplied to the input respectively. For all these methods, the operations are applied element-wise, hence the name feature-wise transformations \cite{dumoulin2018feature-wise}.


\begin{figure}[h!]
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{concat.png}
        \caption{Concatenation}
        \label{}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{add.png}
        \caption{Addition}
        \label{}
    \end{subfigure}
    \begin{subfigure}[b]{.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{mul.png}
        \caption{Multiplication}
        \label{}
    \end{subfigure}    
    \caption{Feature-wise transformations \cite{ruderOverviewMultiTaskLearning2017}}
    \label{}
\end{figure}

Broadly speaking, \gls{mlt} methods can be categorized along several dimensions, including the learning paradigm (e.g., supervised or unsupervised), the type of tasks (e.g., classification or regression), and the nature of the input space. In this work, we focus primarily on supervised tasks, which also represent the most widely studied setting in the \gls{mlt} literature \cite{zhangSurveyMultiTaskLearning2021}.
As we will explore in the next section, our primary task of interest is the prediction of gene expression profiles following a perturbation, which can be formulated as a regression problem. The input consists of a cell’s baseline (or "vehicle") gene expression profile, and the output corresponds to the gene expression profile after the perturbation is applied. The perturbation itself is represented by a condition vector, typically implemented as a one-hot encoding that specifies the type of perturbation administered to the cell.

Formally speaking, for supervised tasks with the same input space, we can define $m$ learning tasks $\{T_{i}\}_{i=1}^m$, and $\mathcal{D}_i$ as the accompanying dataset for the $i$th task, consisting of $n_i$ samples, i.e., $\mathcal{D}_i = \left\{(x_j^i, y_j^i)\right\}_{j=1}^{n_i}$, where $x_j^i$ is the $j$th input sample and $y_j^i$ is its corresponding label.
The loss for the $i$th task can be formulated as $\mathcal{L}_i(\{\theta_i, \theta_{sp}\}, \mathcal{D}_i)$, where $\theta_i$ are the task-specific parameters and $\theta_{sp}$ are the shared parameters.
The goal of \gls{mlt} is to learn a set of parameters $\theta$ that minimizes the total loss across all tasks, i.e.,

\[
\theta = \arg\min_{\theta} \sum_{i=1}^m \mathcal{L}_i(\theta_i, \mathcal{D}_i)
\]

, where $\theta = \{\theta_{sp}, \theta_1, \dots, \theta_m\}$ represents the total set of model parameters.
% 


\section{Perturbation modeling objectives}

In the field of perturbation modeling, there are four main objectives that can be outlined \cite{gavriilidisMinireviewPerturbationModelling2024, jiMachineLearningPerturbational2021, heumos2023best}.

The prediction of unseen omics signatures and phenotypic changes after a perturbation \footnote{In the case of chemical perturbations, the term perturbation refers to the specific drug applied. However, for the purposes of the \gls{ood} task, a change in dosage of the same drug is also considered a distinct perturbation. Throughout this study, we treat each unique combination of drug and dosage as a separate perturbation.} is applied to either a cell line (bulk omics) or individual cells (single-cell omics) is considered the primary objective, often referred to as \gls{ood}. Regarding omics signatures, scGen is a well-known model that has served as a baseline for perturbed single-cell transcriptomics prediction. For phenotypic changes, this could refer to cell viability as a function of drug dosage, typically quantified by IC50 values. DeepDSC \cite{li2019deepdsc} is another example, a deep neural network that predicts the drug sensitivity of cancer cell lines based on their gene expression profiles and a compound descriptor. This compound descriptor is represented as Morgan fingerprints\footnote{Morgan fingerprints, also known as extended-connectivity fingerprints (ECFP), are a type of molecular fingerprint used in cheminformatics to represent the structure of molecules in a computer-readable format. They encode the structural features into a binary vector \cite{morgan1965generation}}, capturing the 1D and 2D structure of the compound.

%The second objective is related to the prediction of the mode-of-action of the perturbation. This could entail predicting the pathway mechanisms and the target proteins that will be activated or inhibited by the perturbation. Understanding to what kind of proteins a drug can bind to and the cascade events triggered by this interaction is fundamental for drug discovery and repurposing. DeepDTAGen, is a multi-task model, that is able to predict the biding affinity of a drug to a protein, and to generate new drug candidates, represented with SMILES strings \footnote{SMILES stands for Simplified Molecular Input Line Entry System. It's a way to represent a chemical molecule as a text string using ASCII characters. For example, ethanol (CH₃CH₂OH) can be represented as the string "CCO"}, based on a target protein \cite{shah2025deepdtagen}.


The second objective concerns the prediction of a perturbation's mode of action. This involves identifying the signaling pathways and specific target proteins that are activated or inhibited in response to a given perturbation. Understanding which proteins a drug interacts with, and the downstream cascade of molecular events it initiates, is fundamental for drug discovery and repurposing.
DeepDTAGen \cite{shah2025deepdtagen} is a multi-task model designed to address this challenge. It predicts the binding affinity between a drug and a target protein, and also generates novel drug candidates represented as SMILES strings\footnote{SMILES stands for Simplified Molecular Input Line Entry System. It is a text-based representation of molecular structures. For example, ethanol (CH₃CH₂OH) can be represented as the string "CCO" in SMILES format.}, conditioned on a given protein target.

Perturbation interaction prediction, that can be highly beneficial for combinatorial treatments, is treated as the third objective. The goal is to predict how different perturbations interact with each other, which is crucial for understanding drug-drug interactions and potential interlinked side effects. This can involve predicting whether two drugs will have synergistic or antagonistic effects when administered together. For example, the DeepSynergy model predicts a synergy score having as inputs the gene expression profiles of a cell line and the chemical descriptors of two drugs \cite{preuer2018deepsynergy}. The synergy score quantifies the deviation of an experimentally observed response surface from one predicted by a theoretical reference model, such as Loewe Additivity \cite{loewe1953problem}, Bliss Independence \cite{bliss1939toxicity}, Highest Single Agent (HSA) \cite{tan2012systematic}, or the more recent Zero Interaction Potency (ZIP) \cite{yadav2015searching}.
% I could elaborate more on the last ones, what is loewe additivity and such

The fourth objective involves the prediction of chemical properties. For instance, the task can be formulated to design de novo chemical compounds that can induce a desired perturbed gene expression profile. PerturbNet \cite{yuPerturbNetPredictsSinglecell2022} is a model capable of addressing this challenge. It first compresses the feature spaces of both transcriptomic profiles and chemical structures using autoencoders. These two modalities are then linked via a conditional invertible neural network (cINN).
By operating the cINN in reverse, the model enables counterfactual predictions, allowing the exploration of the chemical feature space for perturbations likely to produce a specified gene expression response. In this way, the task serves as a conceptual bridge between biology and chemistry, linking molecular structure to phenotypic effect.

\section{Multi-task learning and perturbation modeling}

As mentioned by \cite{jiMachineLearningPerturbational2021,gavriilidisMinireviewPerturbationModelling2024}, \gls{mlt} can be considered a powerful ML/DL approach that can be promising to be applied for perturbation modeling. It is worth mentioning that for the NCI-DREAM challenge \cite{costello2014community}, addressing the drug sensitivity of unseen cell lines, a Bayesian \gls{mlt} approach was considered to perform the best \cite{schrod2024codex}. 

In addition to the categorization of perturbation modeling objectives, single-cell analysis tasks, such as gene regulatory network (GRN) inference, cell clustering, and multi-modal integration, can be highly beneficial when incorporated into a \gls{mlt} framework. These tasks provide complementary biological context that can enhance the performance and interpretability of perturbation modeling.
For example, UnitedNet \cite{tangExplainableMultitaskLearning2023} has demonstrated strong performance in cross-modal prediction and cell-type classification by leveraging multi-omics data within an \gls{mlt} architecture. Similarly, scPreGAN \cite{weiScPreGANDeepGenerative2022} integrates cell type classification as an auxiliary task to improve the generation of perturbed single-cell transcriptomic profiles, illustrating the value of combining single-cell tasks with perturbation modeling objectives.

Solving multiple tasks together can be challenging when they operate on different levels of granularity. For example, prediction of cell viability or drug sensitivity with IC50 values is considered a population-level task, while prediction of single-cell gene expression after a perturbation is a cell-level task. For the former, available datasets provide information about the gene expression profiles of cell lines, along with the chemical compound and the corresponding IC50 values. However, for single-cell perturbation response prediction, a corresponding population-level phenotype (like IC50) from the same experiment is often not directly available. Solving these tasks simultaneously would require bridging bulk with single-cell omics, taking into account the technical variations between the experimental procedures of data acquisition.

On the other hand, the task of predicting bulk-level perturbation responses could be integrated with other population-level tasks such as cell viability, drug sensitivity, synergy prediction, and target/pathway prediction. Datasets that could provide the required information for this bulk analysis by intersecting cell lines include the LINCS L1000 \cite{subramanian2017next} dataset, which consists of 689,831 microarray measurements from 170 different cell lines treated with 20,065 compounds; the Genomics of Drug Sensitivity in Cancer (GDSC) \cite{iorio2016landscape}, which catalogues genomic profiles of 639 human cancer cell lines and their drug response data to 130 drugs; and the large-scale oncology screen produced by Merck \& Co. \cite{o2016unbiased}, which includes 23,062 samples, where each sample consists of two compounds and a cell line.

Instead of treating perturbation objectives as independent tasks, the objectives themselves can be formulated within a \gls{mlt} framework. For example, by defining the prediction of gene expression for a particular perturbation as a task, \gls{mlt} is implicitly utilized by models such as scVIDR \cite{kanaGenerativeModelingSinglecell2023} and CODEX \cite{schrod2024codex}. These models aim to perform this task across multiple perturbations using the same model and by encoding the perturbation as a conditional signal. Another example of division of a specific perturbation objective is STAMP \cite{gaoSubtaskDecompositionbasedLearning2024}, a multi-task model that predicts the differential effect of a perturbation relative to the control gene expression profile. To achieve this, three tasks have been identified: a) which genes are differentially expressed, b) the magnitude of the differential expression, and c) the direction of the differential expression. The model is trained to predict these three tasks simultaneously, allowing for a more comprehensive understanding of the perturbation effect.


% Aside from this categorization of perturbation modeling objectives, there could be other ways of task definition that can lead to the usage of multi-task learning. For example, single, multiple perturbations.

% There have been several instances that multi-task learning has been implicitly or explicitly applied, involving single-cell tasks as well.
% - UnitedNet
% - scpregan uses cell type classification 
% - bayesian multi task won the challenge
% - codex solves for multiple perturbations
% - scvidr as well
% - mlt in drug design paper
% - stamp paper
% should I mention how would be possible to solve simultaneously a task and its reversed task? For example, given an omics signature predict something, and given a perturbed omics signature predict the chemical compound used. Isn't this a class since the prediction of the second is the condition to predict the first? But cinn is something that could work for this.

%sequential, parallel, soft, hard parameter sharing

\section{Method}

Based on the previous analysis of potential integration of perturbation objectives, emphasis has been given to the single-cell 
use case, as it has been the most explored in the literature due to the recent advancements of single-cell technology. More specifically, we define the prediction of the unseen single-cell gene expression after a perturbation is applied as a task, and we will explore designing a model that can achieve this for a set of perturbations. Similarly to the drug-protein study \cite{allenspach2024neural}, where the prediction of the binding affinity between a drug and a protein corresponds to a different task for each protein, we will treat each perturbation as a separate task. 

A typical dataset for this task consists of transcriptomic profiles obtained from \gls{sc} across multiple biological contexts, such as different cell types, perturbations, dosages, studies, or species, under both control and perturbed conditions. The objective is to predict the perturbed gene expression profile of a held-out context, given its control-state profile and the kind of perturbation.
To accomplish this, the model learns the effect of perturbations from the remaining (seen) contexts and generalizes this knowledge to unseen ones. This setting enables the evaluation of a model's ability to extrapolate known perturbation effects to new biological or experimental domains and represents the primary objective of perturbation modeling, the \gls{ood}.

% why the perturbation has been integrated not at the input but the decoder? 

% some models are able to predict for unseen perturbation, not only unseen cell, this should mention, and why we followed this approach, the mlt for drug design is the case that the model can for unseen cell and unseen perturbation.

In our approach, we aim to decouple the perturbation effect by constructing a perturbation-free latent space, while explicitly modeling the perturbation response through a conditioning signal that represents the type of perturbation.
The perturbation is represented as a one-hot encoded vector, where, for a dataset with N perturbations, the conditioning vector has length N+1, with an extra entry representing the control condition.


\begin{wrapfigure}{r}{0.45\textwidth}
  \begin{center}
    \includegraphics[width=.4\textwidth]{film_layers.png}
  \end{center}
  \caption{FiLM \cite{dumoulin2018feature-wise}}
\end{wrapfigure}

About the conditioning of the task, as we have seen at \crefwithname{sec:mlt}, we have explored the application of conditional affine transformation, a combination of multiplicative and additive conditioning, that shifts and scales the input element-wise. It is efficient in terms of scaling and parameters compared to multi-head architectures, where each task has its dedicated network to generate the output of the task . This approach is named as FiLM, for Feature-wise Linear Modulation \cite{dumoulin2018feature-wise, perez2018film}:

\[ \text{FiLM(x)} = \gamma (z) \odot x + \beta (z) \]

, where $\gamma$, and $\beta$ are learnable parameters generated by the so called FiLM generator, that takes as input a condition $z$ (e.g. a vector that indicates the task), and $x$ is the input to be transformed. 
A FiLM layer is the application of the FiLM transformation to the input of a layer, where the parameters $\gamma$ and $\beta$ can be generated by a common or layer-specific FiLM generator.   Then the result of the transformation is propagated to the rest of the network.


% \begin{figure}[h!]
%     \centering
%     \begin{subfigure}[t]{0.48\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{film_layers.png}
%         \caption{Illustration of the FiLM layer}
%         \label{}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[t]{0.48\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{film_gen.png}
%         \caption{A common FiLM generator used across FiLM layers}
%         \label{}
%     \end{subfigure}
%     \caption{Illustration of the FiLM \cite{dumoulin2018feature-wise}}
%     \label{fig:film}
% \end{figure}

% \begin{figure}[h!]
%     \centering
%     \includegraphics[width=0.5\textwidth]{film_layers.png}
%     \caption{Illustration of the feature-wise transformation \cite{dumoulin2018feature-wise}}
%     \label{fig:film}
% \end{figure}


Our baseline architecture is built around an autoencoder, and the conditioning signal is integrated via FiLM layers fused into the decoder (\verb|MTAe|), named as \verb|MTAe|. The modulation parameters $\gamma$ and $\beta$ are learned independently for each fusion point with a dedicated FiLM generator.
During training, the model learns to reconstruct the perturbed gene expression profiles from the control profiles, while the FiLM layers modulate the decoder's hidden layers based on the perturbation type.
The loss is the reconstruction loss of the autoencoder, which is the mean squared error between the input and the output of the decoder:
\[
\mathcal{L}_{\text{recon}} = \frac{1}{N} \sum_{i=1}^{N} ||x_i - \hat{x}_i||^2 \]
, where $x_i$ and $\hat{x}_i$ are the input and the reconstructed gene expression profile respectively, and $N$ is the number of samples.

% I could mention why the condition isn't integrated at the first layers?

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{biorender_film_architecture.png}
    \caption{Illustration of the multi-task architecture. The encoder is shared across all tasks, while the decoder is conditioned by the task-specific FiLM layers. In this example, only two film layers are integrated in the first two hidden layers of the decoder. The FiLM generator takes as input a conditioning representation of the perturbations (e.g. one-hot encoded), and outputs the modulation parameters $\gamma$, and $\beta$ for the FiLM layers. Created in  \url{https://BioRender.com}}
\end{figure}
% I have to document the losses


We have explored several variations of this approach, all of which maintain the decoder architecture with the inclusion of FiLM-based conditioning for all the hidden layers of the decoder. These variations can be split to three main groups, a) adversarial autoencoders, b) optimal transport, c) Variational Autoencoders (VAEs).

\subsection{Adversarial autoencoders (AeAdv)}

In our adversarial autoencoder variations, we enforce structure in the latent space via an adversarial loss. The architecture builds on the previously described autoencoder with FiLM layers, extended with a discriminator. The discriminator is trained to distinguish between encoded latent vectors and samples from a target distribution, while the encoder is trained adversarially to fool the discriminator. This encourages the latent space to match the desired target distribution.

In the \verb|MTAeAdv| architecture, we aim to explicitly model a perturbation-free latent space. Here, the discriminator is trained to distinguish between latent representations of control and perturbed gene expression profiles, while the encoder attempts to make them indistinguishable. This encourages the latent space to be agnostic to perturbation.

In contrast, the \verb|MTAeAdvG| architecture enforces a Gaussian prior on the latent space. The discriminator differentiates between latent vectors from the encoder and samples from a fixed multivariate Gaussian, while the encoder learns to match this distribution.

The total loss for the adversarial autoencoder is a combination of the reconstruction loss and the adversarial loss, defined as:
\[\mathcal{L}_{\text{Adv}} = (1 - \lambda) \mathcal{L}_{\text{recon}} +  \lambda \mathcal{L}_{\text{adv}}\]
, where $\lambda$ is a hyperparameter that controls the trade-off between reconstruction and adversarial loss, and $\mathcal{L}_{\text{adv}}$ is the adversarial loss, which can be defined as the binary cross-entropy loss between the discriminator's predictions and the true labels (1 for real samples, 0 for generated samples):
\[\mathcal{L}_{\text{adv}} = -\frac{1}{N} \sum_{i=1}^{N} \left[ y_i \log(D(z_i)) + (1 - y_i) \log(1 - D(z_i)) \right]\]
, where $D(z_i)$ is the discriminator's prediction for the $i$th latent vector $z_i$, and $y_i$ is the true label (1 for control, 0 for perturbed).

% \begin{figure}
%     \centering
%     \begin{subfigure}[t]{0.48\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{ae_gauss_sketch.png}
%         \caption{}
%         \label{}
%     \end{subfigure}
%     \hfill
%     \begin{subfigure}[t]{0.48\textwidth}
%         \centering
%         \includegraphics[width=\textwidth]{ae_adv_sketch.png}
%         \caption{}
%         \label{}
%     \end{subfigure}
%     \caption{Adversarial autoencoders}
%     \label{}
% \end{figure}

\subsection{Optimal transport (OT)}

Another set of architectural variations incorporates optimal transport to address the lack of paired samples in \gls{sc}. Because the same cell cannot be sequenced both before and after a perturbation, we lack true one-to-one correspondences between control and perturbed conditions. As a result, modeling must rely on comparing distributions rather than individual cell-level changes.

To mitigate this, we use optimal transport to approximate correspondences between distributions. Specifically, for a given sample from the control distribution, a matching sample from the perturbed distribution is assigned based on OT. This pseudo-pairing allows us to reformulate the training objective: instead of reconstructing the input (as in a standard autoencoder), the model is trained to map control cells to their OT-matched counterparts in the perturbed distribution.

The loss is the mean squared error between the input and the output of the decoder, defined as:

\[
\mathcal{L}_{\text{OT}} = \frac{1}{N} \sum_{i=1}^{N} ||x_i - \hat{x}_i||^2 
\]

, where $x_i$ is the input gene expression profile, $\hat{x}_i$ is the paired perturbed gene expression profile, and $N$ is the number of samples. 

Compared to the previous architectures, the perturbed gene expression profiles aren't used as inputs to be reconstructed. Instead, they are used as a target distribution to be mapped given the control gene expression profile and the type of the perturbation. This approach is named as \verb|MTAeOT|. Additionally, we have attempted to pretrain the model with the \verb|MTAe| architecture and then fine-tune it with the \verb|MTAeOT| architecture. This approach is named as \verb|MTAePlusOT|.

% \begin{figure}
%     \centering
%     \includegraphics[width=\textwidth]{ae_ot_sketch.png}
%     \caption{Using optimal transport to fine-tune the MTAe architecture (MTAePlusOT)}
% \end{figure}

\subsection{Variational Autoencoder (VAE)}

The last set of variations involves the inclusion of \gls{vae}. The architecture builds upon the previously described autoencoder framework augmented with FiLM layers, while additionally incorporating a VAE loss to regularize the latent space. The VAE loss is defined as the sum of the reconstruction loss and the Kullback--Leibler (KL) divergence between the learned latent distribution and a standard normal prior:

\[
\mathcal{L}_{\text{VAE}} = \mathbb{E}_{q_\phi(z|x)}[\log p_\theta(x|z)] - D_{\text{KL}}(q_\phi(z|x) \,\|\, p(z))
\]

Here, $q_\phi(z|x)$ is the encoder's approximation of the posterior over latent variables, $p_\theta(x|z)$ is the decoder's likelihood of reconstructing the input, and $p(z) \sim \mathcal{N}(0, I)$ is the prior over latent variables. This model is named as \verb|MTVae|, and as we have described above with the optimal transport use case, we have the \verb|MTVaeOT| and \verb|MTVaePlusOT| architectures.

% \begin{figure}
%     \centering
%     \includegraphics[width=0.8\textwidth]{vae_sketch.png}
%     \caption{VAE}
% \end{figure}



\section{Current single-cell perturbation modeling methods}
\label{sec:benchmark_models}

Several approaches have been proposed in the literature to address the \gls{ood} prediction task. Among these, we selected the following representative methods to benchmark and compare against our multi-task learning architectures: a) scGen \cite{lotfollahiScGenPredictsSinglecell2019}, b) scVIDR \cite{kanaGenerativeModelingSinglecell2023}, c) scPreGAN \cite{weiScPreGANDeepGenerative2022}, and d) scButterfly \cite{caoScButterflyVersatileSinglecell2024}.

\subsection{scGen}

scGen's architecture is based on a \gls{vae} that learns a probabilistic latent space representation of the gene expression profiles. 
The perturbation effect is modeled as a vector $\delta$, calculated as the mean of the differences between the latent vectors of the perturbed and control gene expression profiles. Then, the latent perturbed gene expression profile of a held-out cell type, $\hat{z}$,  is generated by adding this perturbation vector, $\delta$, to the latent vector of the control profile, $z$, using $\hat{z} = z + \delta$. Finally, the perturbed gene expression is obtained by decoding the generated latent vector, $\hat{z}$, using the decoder of the \gls{vae}. This approach allows for the generation of new perturbed profiles by manipulating the latent space representation using vector arithmetic.

\subsection{scVIDR}
 

A key limitation of scGen is the absence of explicit cell-type-specific modeling, which can reduce its ability to generalize to unseen cell types with distinct perturbation responses.
scVIDR addresses this by incorporating cell-type-aware perturbation estimation. Rather than computing a single global perturbation vector $\delta$ based only on the condition labels, scVIDR fits a linear regression model that captures how perturbation vectors vary across cell types.
For each training cell type $i$, the perturbation vector is defined as $\delta_i = \hat{z}_i - z_i$,
where $z_i$​, and $\hat{z}_i$ are the mean latent representation of the control, and perturbed cells of type $i$ respectively.
A linear model is then trained to predict $\hat{\delta}_i$​ from $z_i$, i.e., $\hat{\delta}_i = f(z_i)$.


Once trained, this model can predict the perturbation vector $\delta_A$​ for an unseen cell type $A$, using only its control-state latent representation $z_A$, i.e., $\hat{\delta}_A = f(z_A)$.
This cell-type-aware prediction improves generalization by allowing the model to tailor the perturbation response based on the control-state context of each cell type.

scVIDR can also predict the gene expression profile for multiple dosages. Similarly, scVIDR fits a linear regression model to predict the perturbation vector $\hat{\delta}_c$ across cell types, but in this case, the conditions are the lowest and the highest dosage. Intermediate dosages are then calculated by log linearly interpolating on the $\hat{\delta}_c$.

Regarding interpretability, the bottleneck of the non-linear mapping from the latent space to the gene expression space is replaced by a linear one, utilizing a sparse linear regression model. This is approximated by a weight matrix $\hat{W}_{VAE}$, with dimensions $MxG$ where $M$ is the number of latent variables and $G$ is the number of genes. Then this matrix is used to examine the contribution of the latent variables to the gene expression profile, using the following equation:

\[\text{gene score} = \hat{\delta}_c^T \hat{W}_{VAE}\]

A higher gene score indicates a bigger change at the expression level of the gene if the dosage increases.

\subsection{scPreGAN}

scPreGAN integrates an autoencoder with a \gls{gan} framework to predict \gls{sc} data under perturbations. The architecture consists of a shared encoder and two generators, one for each condition (control and perturbed). To align the generated distributions with the real data, the model employs two discriminators, each associated with a specific condition.

The encoder, which is shared across both conditions, learns a perturbation-free latent representation that captures high-level biological features common to both states. The generators then incorporate condition-specific perturbation effects to reconstruct the gene expression profiles from the latent space. The discriminators are trained to distinguish between real and generated samples, while the generators are optimized adversarially to produce realistic reconstructions that fool their respective discriminators.


\subsection{scButterfly}


scButterfly is a generative adversarial model built on a dual-aligned \gls{vae} architecture, designed for cross-modal translation in single-cell data. The model has demonstrated strong performance in translating between transcriptomic and chromatin accessibility profiles, as well as between transcriptomic and proteomic data.

Its architecture consists of two \gls{vae}s, each pretrained on a specific modality, and a translator component that aligns the latent spaces of the two encoders. The translator is composed of two neural networks, one per modality, each modeling a Gaussian distribution in the latent space. These networks take the encoder's latent representation as input, sample from the modeled distribution, and pass the sample to the decoder of the other modality, enabling cross-modal generation.
After VAE pretraining, the translator is trained to align the latent spaces such that biologically meaningful translation across modalities can be achieved.

Although scButterfly isn't primarily designed for perturbation modeling, the study has demonstrated its potential, by treating control and perturbed expression profiles as two modalities. One of its limitations is the narrow evaluation scope, as it has been tested only on the case of human \gls{pbmc} stimulated by interferon beta (IFN-b) \cite{kanaGenerativeModelingSinglecell2023}.

\section{Evaluation}


% I should mention preprocessing


The models described in \crefwithname{sec:benchmark_models} serve as baselines for evaluating our multi-task learning architectures on the \gls{ood} prediction task.
In contrast to our proposed method, these baseline models are typically designed to predict perturbed gene expression for a single, fixed type of perturbation, and lack the ability to condition on varying perturbation types. An exception is scVIDR, which can condition on different dosages of a given drug. This allows a single scVIDR model to predict responses across multiple perturbations
(we refer to the dosage-aware version of the model as \verb|vidrMult|, and the single-perturbation version as \verb|vidrSingle|).

Our objective is to explore whether explicitly conditioning on the perturbation type, thus enabling multi-perturbation response prediction, within a multi-task learning framework can lead to improved performance on the \gls{ood} prediction task.
We extend this evaluation across multiple biological contexts, including cell types, and species, to assess the robustness and generalization capabilities of our approach.

We have used two categories of evaluation metrics to compare the predicted gene expression profiles to the actual perturbed ones: a) baseline metrics, and b) distance metrics. The baseline metrics include the count of common \gls{degs}, the squared Pearson correlation $R^2$ for mean gene expression levels computed over all the \gls{hvg}, and the $R^2$ score for the top 100 \gls{hvg}. A differentially expressed gene is defined as a gene whose expression distribution differs significantly between the control and perturbed conditions. We have used Scanpy \cite{wolf2018scanpy} to identify \gls{degs}, which applies statistical tests to rank genes based on their test scores. To count common \gls{degs}, we compute the top 100 ranked \gls{degs} for both the predicted and the expected profiles, and then take the intersection of these sets.
The distance metrics capture both point-wise and distributional differences between predicted and actual profiles. These include: (a) Euclidean distance, (b) E-distance, (c) Wasserstein distance, (d) mean pairwise distance, and (e) maximum mean discrepancy (MMD).
The baseline metrics were computed using Scanpy, while the distance metrics were computed with the Pertpy library \cite{heumos2024pertpy}.
To account for model variability, we repeated each experiment three times using different random seeds (1, 2, and 19193), and report the average performance across runs.

For the following analysis, we have selected some of our most promising multi-task architectures, namely \verb|MTAe|, \verb|MTAeAdv|, \verb|MTAeAdvG|, \verb|MTVae| to be visually represented by the evaluation results. For a full comparison of all the models, refer to the supplementary material \crefwithname{sec:appendix_evaluation}. 

\subsection{Single perturbation response prediction}
\label{sec:eval_single_perturbation}

We have evaluated the models on human \gls{pbmc} that have been stimulated by IFN-b interferon (Kang et al. \cite{kanaGenerativeModelingSinglecell2023}). For this dataset, there is only one type of perturbation, and the conditioning signal of our multi-task architectures is a one-hot encoded vector with two entries, one for the control condition and one for the perturbed condition. We have used the provided preprocessed data from scGen study \cite{lotfollahiScGenPredictsSinglecell2019}, which consists of 18.868 cells, and the most highly variable 6.998 genes.
%How the data was preprocessed? Number of samples?

We have tested the models across all the available cell types, training a model from scratch for each use case. To test each one this models, we held-out the perturbed gene expressions of the cell type of interest, and we use the rest to train the model. 

By averaging the results across all the cell types (see \cref{tab:eval_pbmc}), we can see that one of our multi-task versions, \verb|MTAe|, achieved the highest DEGs of $\small{\sim} 75$, while achieving comparable $R^2$ scores to the scVIDR, and scButterfly, as the best performing ones.  The distance metrics show the last ones perform better than \verb|MTAe|, indicating a more representative global structure of the perturbed gene expression profiles. However, \verb|MTAeAdv|, and \verb|MTVae|, seemed to be on par with the best performing models across all metrics, while the optimal transport variations, \verb|MTAeOT|, \verb|MTAePlusOT|, \verb|MTVaeOT|, and \verb|MTVaePlusOT|, performed significantly worse than the rest of the models.
As shown in \cref{fig:eval_pbmc}, we have selected ISG15, a marker gene of IFN-b, as an example gene to visualize the distribution of the predicted and expected gene expression profiles across cell types. However, none of the models seem to capture the expected distribution of the gene expression profile.


% \begin{figure}
%     \centering
%     \includegraphics[width=\textwidth]{multi_task_benchmarking_cell_type_baseline_metrics_pbmc.png}
%     \caption{Kang et al. \cite{kanaGenerativeModelingSinglecell2023}}
%     \label{fig:pbmc_umap}
% \end{figure}

\begin{figure}[h!]
    \centering
    \begin{subfigure}[t]{0.42\textwidth}
        \centering
        \includegraphics[width=\textwidth]{selected_benchmarking_cell_type_baseline_metrics_pbmc.png}
        \caption{Baseline metrics across cell types}
        \label{}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.42\textwidth}
        \centering
        \includegraphics[width=\textwidth]{selected_benchmarking_cell_type_distance_metrics_pbmc.png}
        \caption{Distance metrics across cell types}
        \label{}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/pbmc_split.png}
        \caption{UMAP representation of data splitting}
        \label{}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=.75\textwidth]{violins_pbmc.png}
        \caption{Violin plots of gene expression distributions for gene ISG15}
        \label{}
    \end{subfigure}     
    \caption{Kang et al. \cite{kanaGenerativeModelingSinglecell2023}}
    \label{fig:eval_pbmc}
\end{figure}

\begin{table}[h!]
    \centering
    \scalebox{0.75}{
    \begin{tabularx}{\textwidth}{lXXXXXXXXX}
    \toprule
    model & DEGs & $R^2_{\text{HVG}}$ & $R^2_{\text{HVG20}}$ & $R^2_{\text{HVG100}}$ & Euc & Was & E-dist & MPD & MMD \\
    \midrule
    MTAe & \textbf{75.714} & 0.946 & 0.871 & 0.917 & 0.488 & 0.892 & 0.651 & 0.949 & 0.488 \\
    MTAeAdv & 72.381 & 0.961 & 0.955 & 0.948 & 0.202 & 0.604 & 0.429 & 0.800 & 0.202 \\
    MTAeAdvG & 65.905 & 0.917 & 0.878 & 0.901 & 0.504 & 0.828 & 0.681 & 0.909 & 0.504 \\
    MTAeOT & 41.190 & 0.657 & 0.668 & 0.648 & 0.811 & 0.947 & 0.883 & 0.963 & 0.811 \\
    MTAePlusOT & 37.190 & 0.670 & 0.674 & 0.657 & 0.810 & 0.951 & 0.880 & 0.966 & 0.810 \\
    MTVae & 69.095 & 0.942 & 0.954 & 0.928 & 0.261 & 0.621 & 0.499 & 0.800 & 0.261 \\
    MTVaeOT & 39.571 & 0.669 & 0.678 & 0.663 & 0.813 & 0.955 & 0.883 & 0.966 & 0.813 \\
    MTVaePlusOT & 30.619 & 0.661 & 0.670 & 0.655 & 0.821 & 0.958 & 0.888 & 0.968 & 0.821 \\
    scButterfly & 60.727 & 0.891 & 0.914 & 0.889 & 0.271 & \textbf{0.601} & 0.469 & \textbf{0.779} & 0.271 \\
    scGen & 32.143 & 0.910 & 0.872 & 0.870 & 0.627 & 0.909 & 0.765 & 0.946 & 0.627 \\
    scPreGAN & 35.750 & 0.771 & 0.857 & 0.799 & 0.499 & 0.690 & 0.682 & 0.851 & 0.499 \\
    vidrSingle & 25.536 & \textbf{0.970} & \textbf{0.971} & \textbf{0.961} & \textbf{0.182} & 0.606 & \textbf{0.408} & 0.797 & \textbf{0.182} \\
    \bottomrule
    \end{tabularx}}
    \caption{Averaged across all cell types in Kang et al. \cite{kanaGenerativeModelingSinglecell2023}}
    \label{tab:eval_pbmc}
\end{table}



\subsection{Multiple perturbations response prediction}
\label{sec:eval_multiple_perturbations}

As discussed in \crefwithname{sec:eval_single_perturbation}, our multi-task architectures could not leverage shared information across perturbations in the previous setting, as only a single perturbation was available. To more pragmatically assess their performance, we evaluated the models on the dataset introduced by Nault et al. \cite{nault2021single,nault2022benchmarking}, which includes eleven cell types exposed to eight different dosages of TCDD administered to mice.

The dataset was preprocessed using Scanpy \cite{wolf2018scanpy} by filtering out cells with fewer than 500 total counts and fewer than 720 expressed genes, as well as genes expressed in fewer than 100 cells. The data was log-transformed, for a smoother training process, and the top 5,000 \gls{hvg} were selected.

Each dosage level was treated as a distinct perturbation, with the control condition serving as the baseline. The conditioning signal for our multi-task architectures is a one-hot encoded vector of length nine: one entry for each of the eight dosages, and one for the control condition. For evaluation, we trained a separate model for each cell type, holding out the perturbed gene expression profiles of that cell type for testing. The same model was used to predict responses across all dosages, leveraging the model's ability to condition on perturbation identity.
In contrast, the baseline models, which do not support conditioning on multiple perturbations, required training a separate model for each dosage. An exception is scVIDR, which is designed to handle multiple dosage levels within a single model.

We have averaged the results across all the cell types, and dosages (see \cref{tab:eval_nault}), and similarly with the case of the \crefwithname{sec:eval_single_perturbation}, our multi-task model, \verb|MTAe|, achieved the highest DEGs of $\small{\sim} 20$. scGen achieved the highest $R^2$ scores, but with a very low number of DEGs, and scButterfly's performance remained competitive across all metrics. Our optimal transport variations, performed well on the distance metrics, but poorly on the baseline ones.

\clearpage

\begin{figure}[h!]
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{selected_benchmarking_cell_type_baseline_metrics_nault.png}
        \caption{Baseline metrics across cell types}
        \label{}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{selected_benchmarking_cell_type_distance_metrics_nault.png}
        \caption{Distance metrics across cell types}
        \label{}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{selected_benchmarking_doses_baseline_metrics_nault.png}
        \caption{Baseline metrics across dosages}
        \label{}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=.9\textwidth]{selected_benchmarking_doses_distance_metrics_nault.png}
        \caption{Distance metrics across dosages}
        \label{}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=.9\textwidth]{figures/nault_umap_split_multiple.png}
        \caption{UMAP representation of data splitting for all the dosages}
        \label{}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=.9\textwidth]{figures/nault_umap_split_30.png}
        \caption{UMAP representation of data splitting for the dosage $30 \mu g/kg$}
        \label{}
    \end{subfigure}       
    \caption{Averaged results across all cell types and dosages in Nault et al. \cite{nault2021single,nault2022benchmarking}}
    \label{fig:eval_nault}
\end{figure}

\clearpage

\begin{table}[h!]
    \centering
    \scalebox{0.75}{
    \begin{tabularx}{\textwidth}{lXXXXXXXXX}
    \toprule
    model & DEGs & $R^2_{\text{HVG}}$ & $R^2_{\text{HVG20}}$ & $R^2_{\text{HVG100}}$ & Euc & Was & E-dist & MPD & MMD \\
    \midrule
    MTAe & \textbf{20.341} & 0.862 & 0.792 & 0.833 & 1.386 & 1.217 & 1.116 & 1.050 & 1.386 \\
    MTAeAdv & 13.716 & 0.792 & 0.725 & 0.743 & 1.128 & 1.091 & 1.011 & 1.017 & 1.128 \\
    MTAeAdvG & 18.307 & 0.808 & 0.736 & 0.764 & 1.164 & 1.107 & 1.030 & 1.029 & 1.164 \\
    MTAeOT & 8.652 & 0.608 & 0.642 & 0.590 & 0.925 & 1.006 & 0.951 & 0.998 & 0.925 \\
    MTAePlusOT & 8.519 & 0.613 & 0.644 & 0.596 & \textbf{0.917} & \textbf{1.004} & 0.948 & 0.996 & 0.917 \\
    MTVae & 18.981 & 0.808 & 0.724 & 0.753 & 1.124 & 1.100 & 1.005 & 1.016 & 1.124 \\
    MTVaeOT & 8.163 & 0.614 & 0.642 & 0.593 & 0.929 & 1.009 & 0.952 & 0.998 & 0.929 \\
    MTVaePlusOT & 8.701 & 0.615 & 0.645 & 0.597 & 0.919 & 1.006 & 0.948 & 0.997 & \textbf{0.919} \\
    scButterfly & 16.818 & 0.740 & 0.694 & 0.696 & 0.984 & 1.014 & \textbf{0.944} & \textbf{0.990} & 0.984 \\
    scGen & 6.288 & \textbf{0.915} & \textbf{0.863} & \textbf{0.897} & 2.408 & 1.229 & 1.387 & 1.041 & 2.408 \\
    scPreGAN & 14.511 & 0.599 & 0.596 & 0.562 & 0.972 & 1.019 & 0.969 & 1.000 & 0.972 \\
    vidrMult & 2.352 & 0.870 & 0.837 & 0.852 & 9.295 & 1.358 & 2.425 & 1.054 & 9.295 \\
    vidrSingle & 3.795 & 0.855 & 0.797 & 0.824 & 1.431 & 1.174 & 1.118 & 1.025 & 1.431 \\
    \bottomrule
    \end{tabularx}}
    \caption{Nault et al. \cite{nault2021single,nault2022benchmarking}}
    \label{tab:eval_nault}
\end{table}



% \subsection{Cross-study}

% Robustness against batch effects is a critical aspect of generalization. To evaluate this, we assessed model performance across multiple studies, each potentially introducing technical variation due to differences in experimental protocols, platforms, or sample processing. This cross-study evaluation serves to test the ability of the models to generalize perturbation response predictions beyond dataset-specific biases. To implement this, similarly with the scGen's study, By holding out the perturbed profiles of a given study during training and evaluating the model on that study, we simulate an \gls{ood} setting with respect to study-level batch effects, thereby assessing the robustness and transferability of each approach across independently generated datasets.

\subsection{Cross-species}
\label{sec:eval_cross_species}


Until now, the primary axis of variation along which we evaluated model performance was the condition i.e., control versus perturbed states. To further assess the robustness and generalization of our multi-task architectures, we introduced an additional axis of variation, the species.
Similar to the evaluation performed in the scGen study, we used the dataset from Hagel et al. \cite{hagai2018gene}, which comprises \gls{sc} profiles of bone marrow-derived mononuclear phagocytes from four species, mouse, rat, rabbit, and pig, all perturbed with lipopolysaccharide (LPS) for six hours.

The dataset was obtained preprocessed from the scGen study. To evaluate the models, we followed the same approach as in the \crefwithname{sec:eval_single_perturbation}, but instead of holding out the perturbed gene expression profiles of a cell type, we held out the perturbed gene expression profiles of a species.

By averaging the result across all the species (see \cref{tab:eval_cross_species}), \verb|MTAe|, achieved the highest DEGs of $\small{\sim} 16$. scGen, and scVIDR achieved the highest $R^2$ scores, same as the case of \crefwithname{sec:eval_single_perturbation}, but performed poorly on the distance metrics. \verb|MTVae| achieved the best performance on the distance metrics, relatively high number of DEGs $12.5$, but low $R^2$ scores. The optimal transport variations performed well on the distance metrics, but poorly on the baseline ones, similarly to the case of \crefwithname{sec:eval_multiple_perturbations}.

\begin{table}[h!]
    \centering    
    \scalebox{0.75}{
    \begin{tabularx}{\textwidth}{lXXXXXXXXX}
    \toprule
    model & DEGs & $R^2_{\text{HVG}}$ & $R^2_{\text{HVG20}}$ & $R^2_{\text{HVG100}}$ & Euc & Was & E-dist & MPD & MMD \\
    \midrule
    MTAe & \textbf{16.083} & 0.740 & 0.559 & 0.481 & 0.930 & 1.008 & 0.962 & 0.995 & 0.930 \\
    MTAeAdv & 11.250 & 0.579 & 0.465 & 0.365 & 0.865 & 0.919 & 0.929 & 0.957 & 0.865 \\
    MTAeAdvG & 12.500 & 0.708 & 0.533 & 0.456 & 0.921 & 0.985 & 0.958 & 0.987 & 0.921 \\
    MTAeOT & 7.500 & 0.483 & 0.432 & 0.304 & 0.899 & 0.932 & 0.948 & 0.966 & 0.899 \\
    MTAePlusOT & 8.000 & 0.480 & 0.436 & 0.309 & 0.876 & 0.913 & 0.936 & 0.956 & 0.876 \\
    MTVae & 12.500 & 0.652 & 0.498 & 0.413 & \textbf{0.840} & \textbf{0.903} & \textbf{0.916} & \textbf{0.951} & 0.840 \\
    MTVaeOT & 7.417 & 0.479 & 0.423 & 0.302 & 0.895 & 0.929 & 0.946 & 0.964 & 0.895 \\
    MTVaePlusOT & 7.833 & 0.473 & 0.431 & 0.301 & 0.883 & 0.919 & 0.940 & 0.959 & 0.883 \\
    scButterfly & 10.750 & 0.574 & 0.389 & 0.346 & 0.899 & 0.942 & 0.948 & 0.971 & 0.899 \\
    scGen & 7.583 & 0.826 & 0.705 & 0.658 & 2.014 & 1.576 & 1.367 & 1.165 & 2.014 \\
    scPreGAN & 7.250 & 0.443 & 0.374 & 0.276 & 0.914 & 0.945 & 0.955 & 0.973 & 0.914 \\
    vidrSingle & 12.917 & \textbf{0.878} & \textbf{0.711} & \textbf{0.701} & 3.386 & 1.905 & 1.769 & 1.225 & 3.386 \\
    \bottomrule
    \end{tabularx}}
    \caption{Hagel et al. \cite{hagai2018gene}}
    \label{tab:eval_cross_species}
\end{table}


\begin{figure}[h!]
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{selected_benchmarking_cell_type_baseline_metrics_cross_species.png}
        \caption{Baseline metrics across species}
        \label{}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{selected_benchmarking_cell_type_distance_metrics_cross_species.png}
        \caption{Distance metrics across species}
        \label{}
    \end{subfigure}
    % \begin{subfigure}[b]{0.48\textwidth}
    %     \centering
    %     \includegraphics[width=\textwidth]{violins_cross_species.png}
    %     \caption{Violin plots of gene expression distributions for gene Sod2}
    %     \label{}
    % \end{subfigure}     
    \caption{Averaged results across all species in Hagel et al. \cite{hagai2018gene}}
    \label{fig:eval_cross_species}
\end{figure}


% \subsection{Overview}

% \begin{figure}[h!]
%     \centering
%     \includegraphics[width=\textwidth]{pcas.png}
%     \caption{PCA dimensionality reduction of the real unperturbed data, the real perturbed data and the predicted perturbed data.}
%     \label{fig:selected_nault_cell_type_baseline}
% \end{figure}

% scVIDR performance drops for DEGs, and distance metrics, but it performs well for the $R^2$ metrics and stays very consistent, along with scGEN. The multi-task models and scButterfly exhibit greater variability across measurements, but better performance on average. The optimal transport variations performed poorly overall, but were among the best for distance metrics for the Nault et al. \cite{nault2021single,nault2022benchmarking} dataset. 




\section{Conclusion and future work}

%We have tested the models on the \gls{ood} task across cell types, studies, and species. 

In this work, we proposed a multi-task architecture for perturbation modeling in \gls{sc}, capable of conditioning on the perturbation type. This design allows the model to leverage shared information across different perturbations, leading to improved performance on the \gls{ood} prediction task. We benchmarked our models against state-of-the-art methods, including scGen, scVIDR, scPreGAN, and scButterfly.

We also validated the potential of scButterfly in perturbation modeling on the multi-dosage dataset of Nault et al. \cite{nault2021single,nault2022benchmarking}, extending beyond the Kang et al. dataset \cite{kanaGenerativeModelingSinglecell2023}, which was the primary dataset in the original authors' study.

Our base model, \verb|MTAe|, achieved the highest number of \gls{degs} across all experiments (\crefwithname{sec:eval_single_perturbation}, \crefwithname{sec:eval_multiple_perturbations}, and \crefwithname{sec:eval_cross_species}). While no single model consistently outperforms across all metrics, a significant advantage of our multi-task approach is its lower complexity and scalability. It requires training only one model per cell type, rather than one model per perturbation as in the baseline models \cite{allenspachNeuralMultitaskLearning2024}. This makes our approach particularly advantageous for large datasets with many perturbations, as it reduces both computational cost and training time. Future work could further validate this parameter efficiency by applying our approach to larger, more diverse datasets.

A current limitation of our method is its transductive learning with respect to perturbations. Since the perturbation signal is one-hot encoded, the model cannot generalize to unseen perturbations. Future work should explore how inductive representations of perturbations could be integrated into our architecture to enable extrapolation to unseen perturbations.

\section{Code availability}

The code for the models and the experiments is available at \url{https://github.com/thodkatz/thesis}.

\clearpage


%\include{chapter1}
\addcontentsline{toc}{section}{References}
\bibliographystyle{plain}
\bibliography{references.bib}

\clearpage

\appendix

\section{Evaluation of multi-task architectures on the \gls{ood} task}
\label{sec:appendix_evaluation}

\begin{figure}[h!]
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{multi_task_benchmarking_cell_type_baseline_metrics_pbmc.png}
        \caption{Baseline metrics across cell types}
        \label{}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{multi_task_benchmarking_cell_type_distance_metrics_pbmc.png}
        \caption{Distance metrics across cell types}
        \label{}
    \end{subfigure}
    \caption{Evaluation of multi-task architectures on the Kang et al. \cite{kang2018multiplexed}}
    \label{fig:all_multi_task_kang}
\end{figure}

\begin{figure}[h!]
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{multi_task_benchmarking_cell_type_baseline_metrics_nault.png}
        \caption{Baseline metrics across cell types}
        \label{}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{multi_task_benchmarking_cell_type_distance_metrics_nault.png}
        \caption{Distance metrics across cell types}
        \label{}
    \end{subfigure}
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{multi_task_benchmarking_doses_baseline_metrics_nault.png}
        \caption{Baseline metrics across doses}
        \label{}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{multi_task_benchmarking_doses_distance_metrics_nault.png}
        \caption{Distance metrics across doses}
        \label{}
    \end{subfigure}    
    \caption{Evaluation of multi-task architectures on the Nault et al. \cite{nault2021single,nault2022benchmarking}}
    \label{fig:all_multi_task_nault}
\end{figure}

\end{document}