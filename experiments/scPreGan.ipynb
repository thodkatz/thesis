{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scPreGAN.model.util import load_anndata\n",
    "from thesis import DATA_PATH, SAVED_RESULTS_PATH\n",
    "from scPreGAN import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = DATA_PATH / \"pbmc\" / \"pbmc.h5ad\"\n",
    "pbmc_path = SAVED_RESULTS_PATH / \"scPreGAN\" / \"pbmc\"\n",
    "model_path = pbmc_path / \"model\"\n",
    "logging_path = pbmc_path / \"log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_key = 'condition'\n",
    "condition = {\n",
    "    'case': 'stimulated',\n",
    "    'control': 'control'\n",
    "}\n",
    "cell_type_key = 'cell_type'\n",
    "out_of_sample_prediction = True\n",
    "cell_type= 'Dendritic'\n",
    "\n",
    "\n",
    "adata_split, train_data = load_anndata(path=data_path,\n",
    "                condition_key=condition_key,\n",
    "                condition=condition,\n",
    "                cell_type_key=cell_type_key,\n",
    "                out_sample_prediction=out_of_sample_prediction,\n",
    "                prediction_type=cell_type\n",
    "                )\n",
    "control_adata, perturb_adata = adata_split\n",
    "control_pd, control_celltype_ohe_pd, perturb_pd, perturb_celltype_ohe_pd = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6998 7\n",
      "Random Seed:  3060\n",
      "Successfully created the model\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "n_features = control_pd.shape[1]\n",
    "n_classes = control_adata.obs[cell_type_key].unique().shape[0]\n",
    "print(n_features, n_classes)\n",
    "\n",
    "model = Model(n_features=n_features, n_classes=n_classes, use_cuda=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100/20000] adv_loss: 0.0063  recon_loss: 0.0566 encoding_loss: 0.0023 G_loss: 0.0652 D_A_loss: -0.1936  D_B_loss: 0.0014\n",
      "[200/20000] adv_loss: 0.0064  recon_loss: 0.0552 encoding_loss: 0.0009 G_loss: 0.0625 D_A_loss: -0.5743  D_B_loss: 0.2479\n",
      "[300/20000] adv_loss: 0.0060  recon_loss: 0.0521 encoding_loss: 0.0008 G_loss: 0.0589 D_A_loss: -0.6406  D_B_loss: -0.0280\n",
      "[400/20000] adv_loss: 0.0099  recon_loss: 0.0484 encoding_loss: 0.0007 G_loss: 0.0590 D_A_loss: -0.9805  D_B_loss: -0.3194\n",
      "[500/20000] adv_loss: 0.0113  recon_loss: 0.0503 encoding_loss: 0.0007 G_loss: 0.0623 D_A_loss: -1.1277  D_B_loss: -0.4054\n",
      "[600/20000] adv_loss: 0.0108  recon_loss: 0.0475 encoding_loss: 0.0006 G_loss: 0.0589 D_A_loss: -1.1619  D_B_loss: -0.5453\n",
      "[700/20000] adv_loss: 0.0132  recon_loss: 0.0482 encoding_loss: 0.0007 G_loss: 0.0621 D_A_loss: -1.1946  D_B_loss: -0.6219\n",
      "[800/20000] adv_loss: 0.0131  recon_loss: 0.0462 encoding_loss: 0.0008 G_loss: 0.0601 D_A_loss: -1.3608  D_B_loss: -0.6784\n",
      "[900/20000] adv_loss: 0.0103  recon_loss: 0.0490 encoding_loss: 0.0009 G_loss: 0.0601 D_A_loss: -1.2919  D_B_loss: -0.6405\n",
      "[1000/20000] adv_loss: 0.0127  recon_loss: 0.0458 encoding_loss: 0.0013 G_loss: 0.0598 D_A_loss: -1.2540  D_B_loss: -0.4458\n",
      "[1100/20000] adv_loss: 0.0137  recon_loss: 0.0476 encoding_loss: 0.0012 G_loss: 0.0626 D_A_loss: -1.4095  D_B_loss: -1.0352\n",
      "[1200/20000] adv_loss: 0.0143  recon_loss: 0.0478 encoding_loss: 0.0009 G_loss: 0.0630 D_A_loss: -1.5329  D_B_loss: -0.9182\n",
      "[1300/20000] adv_loss: 0.0142  recon_loss: 0.0470 encoding_loss: 0.0013 G_loss: 0.0625 D_A_loss: -1.5436  D_B_loss: -0.7560\n",
      "[1400/20000] adv_loss: 0.0132  recon_loss: 0.0476 encoding_loss: 0.0008 G_loss: 0.0616 D_A_loss: -1.4888  D_B_loss: -0.7492\n",
      "[1500/20000] adv_loss: 0.0157  recon_loss: 0.0473 encoding_loss: 0.0010 G_loss: 0.0639 D_A_loss: -1.4761  D_B_loss: -0.6762\n",
      "[1600/20000] adv_loss: 0.0175  recon_loss: 0.0454 encoding_loss: 0.0010 G_loss: 0.0640 D_A_loss: -1.4171  D_B_loss: -0.8628\n",
      "[1700/20000] adv_loss: 0.0159  recon_loss: 0.0461 encoding_loss: 0.0011 G_loss: 0.0631 D_A_loss: -1.3459  D_B_loss: -0.7823\n",
      "[1800/20000] adv_loss: 0.0199  recon_loss: 0.0469 encoding_loss: 0.0011 G_loss: 0.0680 D_A_loss: -1.6620  D_B_loss: -0.9763\n",
      "[1900/20000] adv_loss: 0.0173  recon_loss: 0.0449 encoding_loss: 0.0015 G_loss: 0.0637 D_A_loss: -1.5563  D_B_loss: -0.9980\n",
      "[2000/20000] adv_loss: 0.0174  recon_loss: 0.0477 encoding_loss: 0.0012 G_loss: 0.0662 D_A_loss: -1.5461  D_B_loss: -0.9148\n",
      "[2100/20000] adv_loss: 0.0157  recon_loss: 0.0487 encoding_loss: 0.0036 G_loss: 0.0680 D_A_loss: -1.4604  D_B_loss: -1.0391\n",
      "[2200/20000] adv_loss: 0.0177  recon_loss: 0.0491 encoding_loss: 0.0011 G_loss: 0.0679 D_A_loss: -1.5559  D_B_loss: -0.9253\n",
      "[2300/20000] adv_loss: 0.0133  recon_loss: 0.0461 encoding_loss: 0.0012 G_loss: 0.0605 D_A_loss: -1.4513  D_B_loss: -1.0001\n",
      "[2400/20000] adv_loss: 0.0137  recon_loss: 0.0465 encoding_loss: 0.0032 G_loss: 0.0634 D_A_loss: -1.6515  D_B_loss: -1.0971\n",
      "[2500/20000] adv_loss: 0.0168  recon_loss: 0.0506 encoding_loss: 0.0019 G_loss: 0.0693 D_A_loss: -1.1259  D_B_loss: -0.8932\n",
      "[2600/20000] adv_loss: 0.0192  recon_loss: 0.0490 encoding_loss: 0.0015 G_loss: 0.0698 D_A_loss: -1.6210  D_B_loss: -1.2570\n",
      "[2700/20000] adv_loss: 0.0226  recon_loss: 0.0449 encoding_loss: 0.0018 G_loss: 0.0693 D_A_loss: -1.5822  D_B_loss: -1.1316\n",
      "[2800/20000] adv_loss: 0.0166  recon_loss: 0.0446 encoding_loss: 0.0013 G_loss: 0.0625 D_A_loss: -1.3336  D_B_loss: -0.8625\n",
      "[2900/20000] adv_loss: 0.0133  recon_loss: 0.0468 encoding_loss: 0.0013 G_loss: 0.0614 D_A_loss: -1.2924  D_B_loss: -0.9542\n",
      "[3000/20000] adv_loss: 0.0194  recon_loss: 0.0470 encoding_loss: 0.0017 G_loss: 0.0681 D_A_loss: -1.4858  D_B_loss: -1.0840\n",
      "[3100/20000] adv_loss: 0.0223  recon_loss: 0.0513 encoding_loss: 0.0017 G_loss: 0.0753 D_A_loss: -1.4858  D_B_loss: -0.8842\n",
      "[3200/20000] adv_loss: 0.0174  recon_loss: 0.0483 encoding_loss: 0.0034 G_loss: 0.0690 D_A_loss: -1.4664  D_B_loss: -1.1848\n",
      "[3300/20000] adv_loss: 0.0129  recon_loss: 0.0496 encoding_loss: 0.0019 G_loss: 0.0643 D_A_loss: -1.1775  D_B_loss: -0.6582\n",
      "[3400/20000] adv_loss: 0.0108  recon_loss: 0.0459 encoding_loss: 0.0019 G_loss: 0.0586 D_A_loss: -0.8184  D_B_loss: -0.1684\n",
      "[3500/20000] adv_loss: 0.0113  recon_loss: 0.0472 encoding_loss: 0.0017 G_loss: 0.0602 D_A_loss: -1.0272  D_B_loss: -0.6530\n",
      "[3600/20000] adv_loss: 0.0138  recon_loss: 0.0464 encoding_loss: 0.0017 G_loss: 0.0619 D_A_loss: -0.8650  D_B_loss: -0.5882\n",
      "[3700/20000] adv_loss: 0.0100  recon_loss: 0.0462 encoding_loss: 0.0016 G_loss: 0.0577 D_A_loss: -0.4065  D_B_loss: -0.6114\n",
      "[3800/20000] adv_loss: 0.0106  recon_loss: 0.0468 encoding_loss: 0.0012 G_loss: 0.0586 D_A_loss: -0.5032  D_B_loss: -0.4748\n",
      "[3900/20000] adv_loss: 0.0059  recon_loss: 0.0446 encoding_loss: 0.0014 G_loss: 0.0519 D_A_loss: -0.0134  D_B_loss: -0.6645\n",
      "[4000/20000] adv_loss: 0.0063  recon_loss: 0.0442 encoding_loss: 0.0013 G_loss: 0.0518 D_A_loss: -0.3697  D_B_loss: -0.5303\n",
      "[4100/20000] adv_loss: 0.0071  recon_loss: 0.0456 encoding_loss: 0.0011 G_loss: 0.0539 D_A_loss: -0.3950  D_B_loss: -0.7059\n",
      "[4200/20000] adv_loss: 0.0069  recon_loss: 0.0476 encoding_loss: 0.0012 G_loss: 0.0557 D_A_loss: -0.2973  D_B_loss: -0.7667\n",
      "[4300/20000] adv_loss: 0.0051  recon_loss: 0.0471 encoding_loss: 0.0011 G_loss: 0.0534 D_A_loss: -0.1214  D_B_loss: -0.2602\n",
      "[4400/20000] adv_loss: 0.0030  recon_loss: 0.0447 encoding_loss: 0.0009 G_loss: 0.0486 D_A_loss: -0.1820  D_B_loss: -0.3035\n",
      "[4500/20000] adv_loss: 0.0039  recon_loss: 0.0461 encoding_loss: 0.0006 G_loss: 0.0506 D_A_loss: -0.3800  D_B_loss: -0.5589\n",
      "[4600/20000] adv_loss: 0.0064  recon_loss: 0.0420 encoding_loss: 0.0007 G_loss: 0.0491 D_A_loss: -0.1104  D_B_loss: -0.4566\n",
      "[4700/20000] adv_loss: 0.0051  recon_loss: 0.0432 encoding_loss: 0.0004 G_loss: 0.0488 D_A_loss: -0.3308  D_B_loss: -0.6143\n",
      "[4800/20000] adv_loss: 0.0078  recon_loss: 0.0447 encoding_loss: 0.0005 G_loss: 0.0529 D_A_loss: -0.3237  D_B_loss: -0.8238\n",
      "[4900/20000] adv_loss: 0.0069  recon_loss: 0.0434 encoding_loss: 0.0006 G_loss: 0.0509 D_A_loss: -0.0255  D_B_loss: -0.9044\n",
      "[5000/20000] adv_loss: 0.0037  recon_loss: 0.0428 encoding_loss: 0.0004 G_loss: 0.0470 D_A_loss: 0.0547  D_B_loss: -0.2889\n",
      "[5100/20000] adv_loss: 0.0049  recon_loss: 0.0414 encoding_loss: 0.0005 G_loss: 0.0467 D_A_loss: -0.4517  D_B_loss: -0.5765\n",
      "[5200/20000] adv_loss: 0.0042  recon_loss: 0.0442 encoding_loss: 0.0005 G_loss: 0.0489 D_A_loss: -0.3452  D_B_loss: -0.4322\n",
      "[5300/20000] adv_loss: 0.0037  recon_loss: 0.0443 encoding_loss: 0.0005 G_loss: 0.0484 D_A_loss: -0.2824  D_B_loss: -0.4148\n",
      "[5400/20000] adv_loss: 0.0038  recon_loss: 0.0430 encoding_loss: 0.0006 G_loss: 0.0474 D_A_loss: 0.1211  D_B_loss: -0.1530\n",
      "[5500/20000] adv_loss: 0.0046  recon_loss: 0.0448 encoding_loss: 0.0004 G_loss: 0.0498 D_A_loss: -0.4007  D_B_loss: -0.1229\n",
      "[5600/20000] adv_loss: 0.0048  recon_loss: 0.0451 encoding_loss: 0.0004 G_loss: 0.0502 D_A_loss: -0.3527  D_B_loss: -0.1498\n",
      "[5700/20000] adv_loss: 0.0039  recon_loss: 0.0425 encoding_loss: 0.0004 G_loss: 0.0468 D_A_loss: -0.3193  D_B_loss: -0.2185\n",
      "[5800/20000] adv_loss: 0.0041  recon_loss: 0.0429 encoding_loss: 0.0005 G_loss: 0.0474 D_A_loss: -0.4979  D_B_loss: -0.3775\n",
      "[5900/20000] adv_loss: 0.0051  recon_loss: 0.0407 encoding_loss: 0.0004 G_loss: 0.0461 D_A_loss: -0.4392  D_B_loss: -0.3969\n",
      "[6000/20000] adv_loss: 0.0045  recon_loss: 0.0438 encoding_loss: 0.0004 G_loss: 0.0487 D_A_loss: -0.4953  D_B_loss: -0.3729\n",
      "[6100/20000] adv_loss: 0.0059  recon_loss: 0.0446 encoding_loss: 0.0003 G_loss: 0.0508 D_A_loss: -0.7160  D_B_loss: -0.5029\n",
      "[6200/20000] adv_loss: 0.0061  recon_loss: 0.0439 encoding_loss: 0.0003 G_loss: 0.0503 D_A_loss: -0.8000  D_B_loss: -0.6097\n",
      "[6300/20000] adv_loss: 0.0046  recon_loss: 0.0414 encoding_loss: 0.0004 G_loss: 0.0463 D_A_loss: -0.6059  D_B_loss: -0.5664\n",
      "[6400/20000] adv_loss: 0.0043  recon_loss: 0.0414 encoding_loss: 0.0006 G_loss: 0.0463 D_A_loss: -0.4877  D_B_loss: -0.5542\n",
      "[6500/20000] adv_loss: 0.0059  recon_loss: 0.0437 encoding_loss: 0.0005 G_loss: 0.0502 D_A_loss: -0.7138  D_B_loss: -0.7150\n",
      "[6600/20000] adv_loss: 0.0062  recon_loss: 0.0431 encoding_loss: 0.0009 G_loss: 0.0503 D_A_loss: -0.8994  D_B_loss: -0.7277\n",
      "[6700/20000] adv_loss: 0.0050  recon_loss: 0.0449 encoding_loss: 0.0005 G_loss: 0.0504 D_A_loss: -0.7846  D_B_loss: -0.2022\n",
      "[6800/20000] adv_loss: 0.0062  recon_loss: 0.0432 encoding_loss: 0.0004 G_loss: 0.0498 D_A_loss: -0.9309  D_B_loss: -0.3468\n",
      "[6900/20000] adv_loss: 0.0056  recon_loss: 0.0443 encoding_loss: 0.0008 G_loss: 0.0507 D_A_loss: -0.7731  D_B_loss: -0.2005\n",
      "[7000/20000] adv_loss: 0.0055  recon_loss: 0.0426 encoding_loss: 0.0005 G_loss: 0.0486 D_A_loss: -0.9109  D_B_loss: -0.1705\n",
      "[7100/20000] adv_loss: 0.0057  recon_loss: 0.0441 encoding_loss: 0.0004 G_loss: 0.0503 D_A_loss: -0.8434  D_B_loss: -0.1608\n",
      "[7200/20000] adv_loss: 0.0051  recon_loss: 0.0421 encoding_loss: 0.0012 G_loss: 0.0485 D_A_loss: -0.8015  D_B_loss: -0.2823\n",
      "[7300/20000] adv_loss: 0.0036  recon_loss: 0.0413 encoding_loss: 0.0005 G_loss: 0.0454 D_A_loss: -0.6023  D_B_loss: -0.2656\n",
      "[7400/20000] adv_loss: 0.0045  recon_loss: 0.0424 encoding_loss: 0.0026 G_loss: 0.0496 D_A_loss: 3.9939  D_B_loss: -0.3475\n",
      "[7500/20000] adv_loss: 0.0039  recon_loss: 0.0426 encoding_loss: 0.0016 G_loss: 0.0480 D_A_loss: -0.4324  D_B_loss: -0.3218\n",
      "[7600/20000] adv_loss: 0.0037  recon_loss: 0.0428 encoding_loss: 0.0009 G_loss: 0.0474 D_A_loss: -0.4016  D_B_loss: -0.3594\n",
      "[7700/20000] adv_loss: 0.0036  recon_loss: 0.0434 encoding_loss: 0.0007 G_loss: 0.0477 D_A_loss: -0.3087  D_B_loss: -0.4361\n",
      "[7800/20000] adv_loss: 0.0035  recon_loss: 0.0443 encoding_loss: 0.0007 G_loss: 0.0485 D_A_loss: -0.3237  D_B_loss: -0.4219\n",
      "[7900/20000] adv_loss: 0.0049  recon_loss: 0.0408 encoding_loss: 0.0005 G_loss: 0.0462 D_A_loss: -0.3591  D_B_loss: -0.4147\n",
      "[8000/20000] adv_loss: 0.0049  recon_loss: 0.0433 encoding_loss: 0.0006 G_loss: 0.0488 D_A_loss: -0.4281  D_B_loss: -0.3880\n",
      "[8100/20000] adv_loss: 0.0041  recon_loss: 0.0422 encoding_loss: 0.0014 G_loss: 0.0476 D_A_loss: -0.3967  D_B_loss: -0.4011\n",
      "[8200/20000] adv_loss: 0.0039  recon_loss: 0.0432 encoding_loss: 0.0012 G_loss: 0.0483 D_A_loss: -0.5450  D_B_loss: -0.5781\n",
      "[8300/20000] adv_loss: 0.0037  recon_loss: 0.0415 encoding_loss: 0.0008 G_loss: 0.0460 D_A_loss: -0.5492  D_B_loss: -0.5099\n",
      "[8400/20000] adv_loss: 0.0034  recon_loss: 0.0483 encoding_loss: 0.0021 G_loss: 0.0539 D_A_loss: -0.6129  D_B_loss: -0.4325\n",
      "[8500/20000] adv_loss: 0.0040  recon_loss: 0.0409 encoding_loss: 0.0009 G_loss: 0.0459 D_A_loss: -0.5929  D_B_loss: -0.4031\n",
      "[8600/20000] adv_loss: 0.0035  recon_loss: 0.0398 encoding_loss: 0.0008 G_loss: 0.0441 D_A_loss: -0.4504  D_B_loss: -0.6297\n",
      "[8700/20000] adv_loss: 0.0035  recon_loss: 0.0416 encoding_loss: 0.0016 G_loss: 0.0467 D_A_loss: -0.4996  D_B_loss: -0.4078\n",
      "[8800/20000] adv_loss: 0.0032  recon_loss: 0.0460 encoding_loss: 0.0016 G_loss: 0.0508 D_A_loss: -0.5580  D_B_loss: -0.2951\n",
      "[8900/20000] adv_loss: 0.0043  recon_loss: 0.0416 encoding_loss: 0.0008 G_loss: 0.0467 D_A_loss: -0.3280  D_B_loss: -0.4315\n",
      "[9000/20000] adv_loss: 0.0036  recon_loss: 0.0438 encoding_loss: 0.0010 G_loss: 0.0483 D_A_loss: -0.2337  D_B_loss: -0.5342\n",
      "[9100/20000] adv_loss: 0.0046  recon_loss: 0.0411 encoding_loss: 0.0013 G_loss: 0.0470 D_A_loss: -0.3584  D_B_loss: -0.4482\n",
      "[9200/20000] adv_loss: 0.0039  recon_loss: 0.0426 encoding_loss: 0.0012 G_loss: 0.0476 D_A_loss: -0.3359  D_B_loss: -0.5039\n",
      "[9300/20000] adv_loss: 0.0035  recon_loss: 0.0440 encoding_loss: 0.0009 G_loss: 0.0484 D_A_loss: -0.4573  D_B_loss: -0.6522\n",
      "[9400/20000] adv_loss: 0.0038  recon_loss: 0.0407 encoding_loss: 0.0019 G_loss: 0.0465 D_A_loss: -0.5302  D_B_loss: -0.5471\n",
      "[9500/20000] adv_loss: 0.0034  recon_loss: 0.0412 encoding_loss: 0.0013 G_loss: 0.0459 D_A_loss: -0.0792  D_B_loss: -0.3737\n",
      "[9600/20000] adv_loss: 0.0032  recon_loss: 0.0415 encoding_loss: 0.0010 G_loss: 0.0458 D_A_loss: -0.1537  D_B_loss: -0.4446\n",
      "[9700/20000] adv_loss: 0.0042  recon_loss: 0.0442 encoding_loss: 0.0008 G_loss: 0.0492 D_A_loss: -0.3776  D_B_loss: -0.5075\n",
      "[9800/20000] adv_loss: 0.0037  recon_loss: 0.0415 encoding_loss: 0.0010 G_loss: 0.0462 D_A_loss: -0.1282  D_B_loss: -0.3254\n",
      "[9900/20000] adv_loss: 0.0037  recon_loss: 0.0422 encoding_loss: 0.0021 G_loss: 0.0479 D_A_loss: -0.3719  D_B_loss: -0.4827\n",
      "[10000/20000] adv_loss: 0.0040  recon_loss: 0.0438 encoding_loss: 0.0012 G_loss: 0.0490 D_A_loss: -0.3685  D_B_loss: -0.5155\n",
      "[10100/20000] adv_loss: 0.0037  recon_loss: 0.0416 encoding_loss: 0.0013 G_loss: 0.0466 D_A_loss: -0.5708  D_B_loss: -0.5489\n",
      "[10200/20000] adv_loss: 0.0034  recon_loss: 0.0423 encoding_loss: 0.0008 G_loss: 0.0466 D_A_loss: -0.4852  D_B_loss: -0.5361\n",
      "[10300/20000] adv_loss: 0.0037  recon_loss: 0.0424 encoding_loss: 0.0008 G_loss: 0.0469 D_A_loss: -0.3523  D_B_loss: -0.5199\n",
      "[10400/20000] adv_loss: 0.0041  recon_loss: 0.0430 encoding_loss: 0.0018 G_loss: 0.0489 D_A_loss: -0.3835  D_B_loss: -0.5691\n",
      "[10500/20000] adv_loss: 0.0046  recon_loss: 0.0424 encoding_loss: 0.0016 G_loss: 0.0485 D_A_loss: -0.3948  D_B_loss: -0.5937\n",
      "[10600/20000] adv_loss: 0.0037  recon_loss: 0.0444 encoding_loss: 0.0010 G_loss: 0.0492 D_A_loss: -0.3865  D_B_loss: -0.4396\n",
      "[10700/20000] adv_loss: 0.0043  recon_loss: 0.0431 encoding_loss: 0.0009 G_loss: 0.0483 D_A_loss: -0.4255  D_B_loss: -0.7502\n",
      "[10800/20000] adv_loss: 0.0039  recon_loss: 0.0432 encoding_loss: 0.0010 G_loss: 0.0480 D_A_loss: -0.4142  D_B_loss: -0.6747\n",
      "[10900/20000] adv_loss: 0.0037  recon_loss: 0.0416 encoding_loss: 0.0013 G_loss: 0.0466 D_A_loss: -0.4717  D_B_loss: -0.6534\n",
      "[11000/20000] adv_loss: 0.0049  recon_loss: 0.0436 encoding_loss: 0.0011 G_loss: 0.0496 D_A_loss: -0.4666  D_B_loss: -0.5919\n",
      "[11100/20000] adv_loss: 0.0048  recon_loss: 0.0429 encoding_loss: 0.0014 G_loss: 0.0492 D_A_loss: -0.4194  D_B_loss: -0.4230\n",
      "[11200/20000] adv_loss: 0.0054  recon_loss: 0.0443 encoding_loss: 0.0017 G_loss: 0.0514 D_A_loss: -0.4255  D_B_loss: -0.4966\n",
      "[11300/20000] adv_loss: 0.0049  recon_loss: 0.0429 encoding_loss: 0.0010 G_loss: 0.0488 D_A_loss: -0.3597  D_B_loss: -0.5215\n",
      "[11400/20000] adv_loss: 0.0049  recon_loss: 0.0453 encoding_loss: 0.0014 G_loss: 0.0516 D_A_loss: -0.4778  D_B_loss: -0.5908\n",
      "[11500/20000] adv_loss: 0.0049  recon_loss: 0.0416 encoding_loss: 0.0011 G_loss: 0.0476 D_A_loss: -0.3120  D_B_loss: -0.4536\n",
      "[11600/20000] adv_loss: 0.0048  recon_loss: 0.0445 encoding_loss: 0.0016 G_loss: 0.0509 D_A_loss: -0.3582  D_B_loss: -0.5156\n",
      "[11700/20000] adv_loss: 0.0049  recon_loss: 0.0443 encoding_loss: 0.0011 G_loss: 0.0503 D_A_loss: -0.6704  D_B_loss: -0.6370\n",
      "[11800/20000] adv_loss: 0.0050  recon_loss: 0.0464 encoding_loss: 0.0013 G_loss: 0.0526 D_A_loss: -0.2973  D_B_loss: -0.5877\n",
      "[11900/20000] adv_loss: 0.0055  recon_loss: 0.0437 encoding_loss: 0.0011 G_loss: 0.0502 D_A_loss: -0.4896  D_B_loss: -0.6990\n",
      "[12000/20000] adv_loss: 0.0063  recon_loss: 0.0456 encoding_loss: 0.0019 G_loss: 0.0538 D_A_loss: -0.4120  D_B_loss: -0.5839\n",
      "[12100/20000] adv_loss: 0.0044  recon_loss: 0.0430 encoding_loss: 0.0011 G_loss: 0.0485 D_A_loss: -0.4371  D_B_loss: -0.3843\n",
      "[12200/20000] adv_loss: 0.0048  recon_loss: 0.0455 encoding_loss: 0.0013 G_loss: 0.0516 D_A_loss: -0.5321  D_B_loss: -0.6530\n",
      "[12300/20000] adv_loss: 0.0056  recon_loss: 0.0453 encoding_loss: 0.0016 G_loss: 0.0525 D_A_loss: -0.6421  D_B_loss: -0.5796\n",
      "[12400/20000] adv_loss: 0.0060  recon_loss: 0.0418 encoding_loss: 0.0018 G_loss: 0.0496 D_A_loss: -0.5349  D_B_loss: -0.5260\n",
      "[12500/20000] adv_loss: 0.0060  recon_loss: 0.0440 encoding_loss: 0.0018 G_loss: 0.0518 D_A_loss: -0.7604  D_B_loss: -0.7254\n",
      "[12600/20000] adv_loss: 0.0063  recon_loss: 0.0439 encoding_loss: 0.0015 G_loss: 0.0517 D_A_loss: -0.7373  D_B_loss: -0.7458\n",
      "[12700/20000] adv_loss: 0.0063  recon_loss: 0.0465 encoding_loss: 0.0015 G_loss: 0.0544 D_A_loss: -0.3225  D_B_loss: -0.4048\n",
      "[12800/20000] adv_loss: 0.0057  recon_loss: 0.0457 encoding_loss: 0.0016 G_loss: 0.0530 D_A_loss: -0.8036  D_B_loss: -0.8252\n",
      "[12900/20000] adv_loss: 0.0058  recon_loss: 0.0480 encoding_loss: 0.0027 G_loss: 0.0565 D_A_loss: -0.6565  D_B_loss: -0.7171\n",
      "[13000/20000] adv_loss: 0.0065  recon_loss: 0.0456 encoding_loss: 0.0018 G_loss: 0.0539 D_A_loss: -0.6394  D_B_loss: -0.3870\n",
      "[13100/20000] adv_loss: 0.0070  recon_loss: 0.0460 encoding_loss: 0.0020 G_loss: 0.0550 D_A_loss: -0.8003  D_B_loss: -0.7280\n",
      "[13200/20000] adv_loss: 0.0060  recon_loss: 0.0453 encoding_loss: 0.0016 G_loss: 0.0529 D_A_loss: -0.7183  D_B_loss: -0.6189\n",
      "[13300/20000] adv_loss: 0.0048  recon_loss: 0.0463 encoding_loss: 0.0016 G_loss: 0.0526 D_A_loss: -0.6359  D_B_loss: -0.7689\n",
      "[13400/20000] adv_loss: 0.0065  recon_loss: 0.0445 encoding_loss: 0.0017 G_loss: 0.0528 D_A_loss: -0.5456  D_B_loss: -0.5987\n",
      "[13500/20000] adv_loss: 0.0060  recon_loss: 0.0485 encoding_loss: 0.0019 G_loss: 0.0564 D_A_loss: -0.4625  D_B_loss: -0.5964\n",
      "[13600/20000] adv_loss: 0.0078  recon_loss: 0.0506 encoding_loss: 0.0023 G_loss: 0.0607 D_A_loss: -0.7218  D_B_loss: -0.7357\n",
      "[13700/20000] adv_loss: 0.0070  recon_loss: 0.0468 encoding_loss: 0.0020 G_loss: 0.0558 D_A_loss: -0.8121  D_B_loss: -0.9389\n",
      "[13800/20000] adv_loss: 0.0059  recon_loss: 0.0468 encoding_loss: 0.0020 G_loss: 0.0547 D_A_loss: -0.6852  D_B_loss: -0.6069\n",
      "[13900/20000] adv_loss: 0.0064  recon_loss: 0.0486 encoding_loss: 0.0022 G_loss: 0.0572 D_A_loss: -0.6468  D_B_loss: -0.8151\n",
      "[14000/20000] adv_loss: 0.0071  recon_loss: 0.0465 encoding_loss: 0.0018 G_loss: 0.0554 D_A_loss: -0.6261  D_B_loss: -0.6453\n",
      "[14100/20000] adv_loss: 0.0083  recon_loss: 0.0469 encoding_loss: 0.0025 G_loss: 0.0576 D_A_loss: -0.7114  D_B_loss: -0.6759\n",
      "[14200/20000] adv_loss: 0.0089  recon_loss: 0.0468 encoding_loss: 0.0026 G_loss: 0.0583 D_A_loss: -0.5125  D_B_loss: -0.4976\n",
      "[14300/20000] adv_loss: 0.0087  recon_loss: 0.0469 encoding_loss: 0.0016 G_loss: 0.0573 D_A_loss: -0.4939  D_B_loss: -0.6711\n",
      "[14400/20000] adv_loss: 0.0095  recon_loss: 0.0469 encoding_loss: 0.0016 G_loss: 0.0580 D_A_loss: -0.6915  D_B_loss: -0.5178\n",
      "[14500/20000] adv_loss: 0.0077  recon_loss: 0.0417 encoding_loss: 0.0025 G_loss: 0.0520 D_A_loss: -0.6102  D_B_loss: -0.9289\n",
      "[14600/20000] adv_loss: 0.0089  recon_loss: 0.0501 encoding_loss: 0.0018 G_loss: 0.0608 D_A_loss: -0.5886  D_B_loss: -0.8473\n",
      "[14700/20000] adv_loss: 0.0074  recon_loss: 0.0472 encoding_loss: 0.0029 G_loss: 0.0575 D_A_loss: -0.6849  D_B_loss: -0.6412\n",
      "[14800/20000] adv_loss: 0.0093  recon_loss: 0.0468 encoding_loss: 0.0020 G_loss: 0.0581 D_A_loss: -0.5919  D_B_loss: -0.6760\n",
      "[14900/20000] adv_loss: 0.0088  recon_loss: 0.0472 encoding_loss: 0.0024 G_loss: 0.0583 D_A_loss: -0.7481  D_B_loss: -1.0009\n",
      "[15000/20000] adv_loss: 0.0089  recon_loss: 0.0470 encoding_loss: 0.0018 G_loss: 0.0577 D_A_loss: -0.6943  D_B_loss: -0.4572\n",
      "[15100/20000] adv_loss: 0.0080  recon_loss: 0.0454 encoding_loss: 0.0022 G_loss: 0.0557 D_A_loss: -0.5361  D_B_loss: -0.9036\n",
      "[15200/20000] adv_loss: 0.0111  recon_loss: 0.0479 encoding_loss: 0.0020 G_loss: 0.0609 D_A_loss: -0.6003  D_B_loss: -0.5622\n",
      "[15300/20000] adv_loss: 0.0080  recon_loss: 0.0493 encoding_loss: 0.0024 G_loss: 0.0598 D_A_loss: -0.5841  D_B_loss: -0.7353\n",
      "[15400/20000] adv_loss: 0.0125  recon_loss: 0.0491 encoding_loss: 0.0020 G_loss: 0.0636 D_A_loss: -0.4957  D_B_loss: -0.6962\n",
      "[15500/20000] adv_loss: 0.0101  recon_loss: 0.0475 encoding_loss: 0.0021 G_loss: 0.0597 D_A_loss: -0.7860  D_B_loss: -0.5981\n",
      "[15600/20000] adv_loss: 0.0107  recon_loss: 0.0485 encoding_loss: 0.0016 G_loss: 0.0608 D_A_loss: -0.6622  D_B_loss: -0.5418\n",
      "[15700/20000] adv_loss: 0.0102  recon_loss: 0.0466 encoding_loss: 0.0019 G_loss: 0.0588 D_A_loss: -0.8707  D_B_loss: -0.7912\n",
      "[15800/20000] adv_loss: 0.0089  recon_loss: 0.0470 encoding_loss: 0.0018 G_loss: 0.0577 D_A_loss: -0.7042  D_B_loss: -0.7836\n",
      "[15900/20000] adv_loss: 0.0100  recon_loss: 0.0454 encoding_loss: 0.0018 G_loss: 0.0571 D_A_loss: -0.8227  D_B_loss: -0.8380\n",
      "[16000/20000] adv_loss: 0.0111  recon_loss: 0.0505 encoding_loss: 0.0019 G_loss: 0.0635 D_A_loss: -0.7675  D_B_loss: -0.6926\n",
      "[16100/20000] adv_loss: 0.0118  recon_loss: 0.0469 encoding_loss: 0.0019 G_loss: 0.0606 D_A_loss: -0.9033  D_B_loss: -1.1483\n",
      "[16200/20000] adv_loss: 0.0123  recon_loss: 0.0505 encoding_loss: 0.0021 G_loss: 0.0649 D_A_loss: -0.8243  D_B_loss: -0.7963\n",
      "[16300/20000] adv_loss: 0.0103  recon_loss: 0.0481 encoding_loss: 0.0021 G_loss: 0.0606 D_A_loss: -0.8186  D_B_loss: -1.0315\n",
      "[16400/20000] adv_loss: 0.0113  recon_loss: 0.0488 encoding_loss: 0.0026 G_loss: 0.0627 D_A_loss: -0.8449  D_B_loss: -0.6875\n",
      "[16500/20000] adv_loss: 0.0106  recon_loss: 0.0500 encoding_loss: 0.0028 G_loss: 0.0635 D_A_loss: -0.8849  D_B_loss: -0.7411\n",
      "[16600/20000] adv_loss: 0.0094  recon_loss: 0.0474 encoding_loss: 0.0020 G_loss: 0.0587 D_A_loss: -0.7104  D_B_loss: -1.0144\n",
      "[16700/20000] adv_loss: 0.0095  recon_loss: 0.0490 encoding_loss: 0.0027 G_loss: 0.0612 D_A_loss: -0.7014  D_B_loss: -0.8630\n",
      "[16800/20000] adv_loss: 0.0133  recon_loss: 0.0485 encoding_loss: 0.0022 G_loss: 0.0640 D_A_loss: -0.9927  D_B_loss: -0.6611\n",
      "[16900/20000] adv_loss: 0.0110  recon_loss: 0.0488 encoding_loss: 0.0021 G_loss: 0.0620 D_A_loss: -1.0401  D_B_loss: -1.1558\n",
      "[17000/20000] adv_loss: 0.0099  recon_loss: 0.0476 encoding_loss: 0.0022 G_loss: 0.0598 D_A_loss: -0.8743  D_B_loss: -1.0405\n",
      "[17100/20000] adv_loss: 0.0126  recon_loss: 0.0490 encoding_loss: 0.0022 G_loss: 0.0637 D_A_loss: -1.1598  D_B_loss: -1.0531\n",
      "[17200/20000] adv_loss: 0.0130  recon_loss: 0.0511 encoding_loss: 0.0039 G_loss: 0.0680 D_A_loss: -1.1176  D_B_loss: -0.8115\n",
      "[17300/20000] adv_loss: 0.0128  recon_loss: 0.0487 encoding_loss: 0.0022 G_loss: 0.0637 D_A_loss: -0.8948  D_B_loss: -0.9947\n",
      "[17400/20000] adv_loss: 0.0123  recon_loss: 0.0501 encoding_loss: 0.0029 G_loss: 0.0653 D_A_loss: -1.0983  D_B_loss: -0.9775\n",
      "[17500/20000] adv_loss: 0.0091  recon_loss: 0.0494 encoding_loss: 0.0034 G_loss: 0.0619 D_A_loss: -0.9282  D_B_loss: -1.0979\n",
      "[17600/20000] adv_loss: 0.0111  recon_loss: 0.0457 encoding_loss: 0.0032 G_loss: 0.0600 D_A_loss: -0.9012  D_B_loss: -0.6981\n",
      "[17700/20000] adv_loss: 0.0128  recon_loss: 0.0517 encoding_loss: 0.0044 G_loss: 0.0689 D_A_loss: -0.9848  D_B_loss: -0.7578\n",
      "[17800/20000] adv_loss: 0.0113  recon_loss: 0.0483 encoding_loss: 0.0027 G_loss: 0.0623 D_A_loss: -0.9931  D_B_loss: -0.8931\n",
      "[17900/20000] adv_loss: 0.0092  recon_loss: 0.0496 encoding_loss: 0.0038 G_loss: 0.0626 D_A_loss: -0.8949  D_B_loss: -0.9231\n",
      "[18000/20000] adv_loss: 0.0095  recon_loss: 0.0483 encoding_loss: 0.0035 G_loss: 0.0614 D_A_loss: -1.1002  D_B_loss: -0.9988\n",
      "[18100/20000] adv_loss: 0.0121  recon_loss: 0.0467 encoding_loss: 0.0028 G_loss: 0.0617 D_A_loss: -1.1290  D_B_loss: -0.9393\n",
      "[18200/20000] adv_loss: 0.0130  recon_loss: 0.0512 encoding_loss: 0.0031 G_loss: 0.0674 D_A_loss: -0.9405  D_B_loss: -0.7638\n",
      "[18300/20000] adv_loss: 0.0114  recon_loss: 0.0495 encoding_loss: 0.0031 G_loss: 0.0640 D_A_loss: -1.3094  D_B_loss: -1.1870\n",
      "[18400/20000] adv_loss: 0.0111  recon_loss: 0.0524 encoding_loss: 0.0030 G_loss: 0.0666 D_A_loss: -1.1218  D_B_loss: -1.0243\n",
      "[18500/20000] adv_loss: 0.0127  recon_loss: 0.0490 encoding_loss: 0.0038 G_loss: 0.0655 D_A_loss: -0.9432  D_B_loss: -0.9759\n",
      "[18600/20000] adv_loss: 0.0117  recon_loss: 0.0476 encoding_loss: 0.0031 G_loss: 0.0624 D_A_loss: -1.0401  D_B_loss: -1.0539\n",
      "[18700/20000] adv_loss: 0.0117  recon_loss: 0.0485 encoding_loss: 0.0031 G_loss: 0.0633 D_A_loss: -1.0358  D_B_loss: -1.1851\n",
      "[18800/20000] adv_loss: 0.0117  recon_loss: 0.0483 encoding_loss: 0.0063 G_loss: 0.0663 D_A_loss: -1.0817  D_B_loss: -1.1200\n",
      "[18900/20000] adv_loss: 0.0117  recon_loss: 0.0502 encoding_loss: 0.0041 G_loss: 0.0660 D_A_loss: -0.9279  D_B_loss: -0.9399\n",
      "[19000/20000] adv_loss: 0.0131  recon_loss: 0.0530 encoding_loss: 0.0034 G_loss: 0.0694 D_A_loss: -1.0514  D_B_loss: -0.8498\n",
      "[19100/20000] adv_loss: 0.0116  recon_loss: 0.0487 encoding_loss: 0.0044 G_loss: 0.0648 D_A_loss: -0.7761  D_B_loss: -0.6747\n",
      "[19200/20000] adv_loss: 0.0131  recon_loss: 0.0477 encoding_loss: 0.0047 G_loss: 0.0655 D_A_loss: -0.9805  D_B_loss: -0.9228\n",
      "[19300/20000] adv_loss: 0.0151  recon_loss: 0.0529 encoding_loss: 0.0034 G_loss: 0.0714 D_A_loss: -1.1786  D_B_loss: -1.0828\n",
      "[19400/20000] adv_loss: 0.0110  recon_loss: 0.0500 encoding_loss: 0.0032 G_loss: 0.0643 D_A_loss: -0.7072  D_B_loss: -0.8691\n",
      "[19500/20000] adv_loss: 0.0146  recon_loss: 0.0479 encoding_loss: 0.0035 G_loss: 0.0660 D_A_loss: -1.1032  D_B_loss: -1.0355\n",
      "[19600/20000] adv_loss: 0.0140  recon_loss: 0.0477 encoding_loss: 0.0031 G_loss: 0.0648 D_A_loss: -0.9574  D_B_loss: -0.9814\n",
      "[19700/20000] adv_loss: 0.0112  recon_loss: 0.0486 encoding_loss: 0.0052 G_loss: 0.0649 D_A_loss: -0.8629  D_B_loss: -0.9599\n",
      "[19800/20000] adv_loss: 0.0156  recon_loss: 0.0494 encoding_loss: 0.0054 G_loss: 0.0703 D_A_loss: -0.9407  D_B_loss: -1.1695\n",
      "[19900/20000] adv_loss: 0.0153  recon_loss: 0.0527 encoding_loss: 0.0054 G_loss: 0.0733 D_A_loss: -1.3071  D_B_loss: -1.0942\n",
      "[20000/20000] adv_loss: 0.0134  recon_loss: 0.0465 encoding_loss: 0.0047 G_loss: 0.0647 D_A_loss: -1.1240  D_B_loss: -1.1421\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "\n",
    "model.train(train_data=train_data, model_path=model_path, logg_path=logging_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting data finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 670 × 6998\n",
       "    obs: 'condition', 'cell_type'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting\n",
    "control_test_adata = control_adata[control_adata.obs[\"cell_type\"] == \"Dendritic\"]\n",
    "pred_perturbed_adata = model.predict(control_adata=control_test_adata,\n",
    "                   cell_type_key=cell_type_key,\n",
    "                   condition_key=condition_key)\n",
    "pred_perturbed_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to evalute the pred_perturbed_adata?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt to use the script from the reproducibility to check differences with the provided scPreGAN. For example, in the reproducibility training script there is `calc_gradient_penalty`, that doesn't exist in the scPreGAN repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  3060\n",
      "No validation.\n",
      "feature length:  6998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/kreshuk/katzalis/conda/miniforge3/envs/thesis/lib/python3.10/site-packages/torch/autograd/graph.py:769: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /opt/conda/conda-bld/pytorch_1724789122112/work/aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100/20000] D_A_loss: -12.2384  D_B_loss: -6.4245 adv_loss: 0.0164  recon_loss: 0.0966 encoding_loss: 0.0112 G_loss: 0.1241\n",
      "[200/20000] D_A_loss: -6.4438  D_B_loss: -6.2872 adv_loss: -0.0150  recon_loss: 0.0786 encoding_loss: 0.0097 G_loss: 0.0733\n",
      "[300/20000] D_A_loss: -5.9235  D_B_loss: -6.2058 adv_loss: -0.0227  recon_loss: 0.0693 encoding_loss: 0.0085 G_loss: 0.0551\n",
      "[400/20000] D_A_loss: -5.4887  D_B_loss: -5.7845 adv_loss: -0.0202  recon_loss: 0.0652 encoding_loss: 0.0072 G_loss: 0.0522\n",
      "[500/20000] D_A_loss: -5.6279  D_B_loss: -5.2396 adv_loss: -0.0214  recon_loss: 0.0648 encoding_loss: 0.0069 G_loss: 0.0503\n",
      "[600/20000] D_A_loss: -5.1888  D_B_loss: -4.8162 adv_loss: -0.0249  recon_loss: 0.0655 encoding_loss: 0.0049 G_loss: 0.0455\n",
      "[700/20000] D_A_loss: -4.6342  D_B_loss: -4.5552 adv_loss: -0.0294  recon_loss: 0.0620 encoding_loss: 0.0043 G_loss: 0.0369\n",
      "[800/20000] D_A_loss: -4.4008  D_B_loss: -4.2186 adv_loss: -0.0351  recon_loss: 0.0585 encoding_loss: 0.0039 G_loss: 0.0273\n",
      "[900/20000] D_A_loss: -4.0063  D_B_loss: -3.9542 adv_loss: -0.0365  recon_loss: 0.0560 encoding_loss: 0.0030 G_loss: 0.0225\n",
      "[1000/20000] D_A_loss: -3.8102  D_B_loss: -3.5816 adv_loss: -0.0381  recon_loss: 0.0582 encoding_loss: 0.0031 G_loss: 0.0232\n",
      "[1100/20000] D_A_loss: -3.5850  D_B_loss: -3.3163 adv_loss: -0.0368  recon_loss: 0.0535 encoding_loss: 0.0026 G_loss: 0.0193\n",
      "[1200/20000] D_A_loss: -3.1507  D_B_loss: -2.9312 adv_loss: -0.0410  recon_loss: 0.0510 encoding_loss: 0.0027 G_loss: 0.0126\n",
      "[1300/20000] D_A_loss: -3.1125  D_B_loss: -2.8386 adv_loss: -0.0404  recon_loss: 0.0542 encoding_loss: 0.0041 G_loss: 0.0179\n",
      "[1400/20000] D_A_loss: -2.6830  D_B_loss: -2.6316 adv_loss: -0.0414  recon_loss: 0.0502 encoding_loss: 0.0033 G_loss: 0.0120\n",
      "[1500/20000] D_A_loss: -2.6226  D_B_loss: -2.4646 adv_loss: -0.0390  recon_loss: 0.0510 encoding_loss: 0.0026 G_loss: 0.0146\n",
      "[1600/20000] D_A_loss: -2.3056  D_B_loss: -2.2193 adv_loss: -0.0329  recon_loss: 0.0515 encoding_loss: 0.0026 G_loss: 0.0212\n",
      "[1700/20000] D_A_loss: -2.7780  D_B_loss: -2.3298 adv_loss: -0.0267  recon_loss: 0.0517 encoding_loss: 0.0026 G_loss: 0.0275\n",
      "[1800/20000] D_A_loss: -2.0636  D_B_loss: -2.0205 adv_loss: -0.0228  recon_loss: 0.0535 encoding_loss: 0.0033 G_loss: 0.0339\n",
      "[1900/20000] D_A_loss: -2.0055  D_B_loss: -1.6751 adv_loss: -0.0255  recon_loss: 0.0533 encoding_loss: 0.0024 G_loss: 0.0302\n",
      "[2000/20000] D_A_loss: -1.6545  D_B_loss: -1.7611 adv_loss: -0.0279  recon_loss: 0.0486 encoding_loss: 0.0019 G_loss: 0.0226\n",
      "[2100/20000] D_A_loss: -1.6895  D_B_loss: -1.3396 adv_loss: -0.0265  recon_loss: 0.0528 encoding_loss: 0.0023 G_loss: 0.0287\n",
      "[2200/20000] D_A_loss: -1.6634  D_B_loss: -1.5566 adv_loss: -0.0270  recon_loss: 0.0451 encoding_loss: 0.0024 G_loss: 0.0204\n",
      "[2300/20000] D_A_loss: -1.7702  D_B_loss: -1.4242 adv_loss: -0.0131  recon_loss: 0.0464 encoding_loss: 0.0022 G_loss: 0.0355\n",
      "[2400/20000] D_A_loss: -1.3372  D_B_loss: -1.4602 adv_loss: -0.0155  recon_loss: 0.0470 encoding_loss: 0.0020 G_loss: 0.0335\n",
      "[2500/20000] D_A_loss: -1.2032  D_B_loss: -1.3258 adv_loss: -0.0094  recon_loss: 0.0460 encoding_loss: 0.0021 G_loss: 0.0386\n",
      "[2600/20000] D_A_loss: -1.3374  D_B_loss: -1.1122 adv_loss: -0.0050  recon_loss: 0.0509 encoding_loss: 0.0027 G_loss: 0.0486\n",
      "[2700/20000] D_A_loss: -1.2797  D_B_loss: -1.3769 adv_loss: 0.0056  recon_loss: 0.0513 encoding_loss: 0.0026 G_loss: 0.0595\n",
      "[2800/20000] D_A_loss: -1.0105  D_B_loss: -1.2236 adv_loss: 0.0053  recon_loss: 0.0458 encoding_loss: 0.0019 G_loss: 0.0530\n",
      "[2900/20000] D_A_loss: -0.8501  D_B_loss: -1.0399 adv_loss: 0.0126  recon_loss: 0.0459 encoding_loss: 0.0021 G_loss: 0.0606\n",
      "[3000/20000] D_A_loss: -0.9309  D_B_loss: -1.1137 adv_loss: 0.0276  recon_loss: 0.0464 encoding_loss: 0.0021 G_loss: 0.0760\n",
      "[3100/20000] D_A_loss: -0.8151  D_B_loss: -1.2141 adv_loss: 0.0304  recon_loss: 0.0485 encoding_loss: 0.0027 G_loss: 0.0816\n",
      "[3200/20000] D_A_loss: -0.7251  D_B_loss: -1.0089 adv_loss: 0.0318  recon_loss: 0.0462 encoding_loss: 0.0015 G_loss: 0.0796\n",
      "[3300/20000] D_A_loss: -1.1203  D_B_loss: -0.9643 adv_loss: 0.0394  recon_loss: 0.0477 encoding_loss: 0.0030 G_loss: 0.0902\n",
      "[3400/20000] D_A_loss: -0.8566  D_B_loss: -1.1168 adv_loss: 0.0483  recon_loss: 0.0479 encoding_loss: 0.0018 G_loss: 0.0980\n",
      "[3500/20000] D_A_loss: -0.6566  D_B_loss: -0.9126 adv_loss: 0.0432  recon_loss: 0.0442 encoding_loss: 0.0025 G_loss: 0.0898\n",
      "[3600/20000] D_A_loss: -0.7868  D_B_loss: -1.0003 adv_loss: 0.0462  recon_loss: 0.0430 encoding_loss: 0.0014 G_loss: 0.0906\n",
      "[3700/20000] D_A_loss: -1.0744  D_B_loss: -1.1743 adv_loss: 0.0444  recon_loss: 0.0463 encoding_loss: 0.0023 G_loss: 0.0930\n",
      "[3800/20000] D_A_loss: -0.9618  D_B_loss: -1.1484 adv_loss: 0.0359  recon_loss: 0.0496 encoding_loss: 0.0017 G_loss: 0.0871\n",
      "[3900/20000] D_A_loss: -1.1725  D_B_loss: -1.0905 adv_loss: 0.0425  recon_loss: 0.0442 encoding_loss: 0.0015 G_loss: 0.0882\n",
      "[4000/20000] D_A_loss: -0.9380  D_B_loss: -0.9412 adv_loss: 0.0371  recon_loss: 0.0428 encoding_loss: 0.0015 G_loss: 0.0814\n",
      "[4100/20000] D_A_loss: -0.9403  D_B_loss: -0.8144 adv_loss: 0.0333  recon_loss: 0.0465 encoding_loss: 0.0018 G_loss: 0.0816\n",
      "[4200/20000] D_A_loss: -1.2106  D_B_loss: -1.0695 adv_loss: 0.0271  recon_loss: 0.0482 encoding_loss: 0.0012 G_loss: 0.0766\n",
      "[4300/20000] D_A_loss: -0.9794  D_B_loss: -0.8906 adv_loss: 0.0285  recon_loss: 0.0447 encoding_loss: 0.0012 G_loss: 0.0744\n",
      "[4400/20000] D_A_loss: -1.4074  D_B_loss: -0.9123 adv_loss: 0.0276  recon_loss: 0.0470 encoding_loss: 0.0014 G_loss: 0.0760\n",
      "[4500/20000] D_A_loss: -0.9145  D_B_loss: -0.8956 adv_loss: 0.0233  recon_loss: 0.0435 encoding_loss: 0.0017 G_loss: 0.0685\n",
      "[4600/20000] D_A_loss: -1.1374  D_B_loss: -1.0717 adv_loss: 0.0221  recon_loss: 0.0436 encoding_loss: 0.0023 G_loss: 0.0680\n",
      "[4700/20000] D_A_loss: -1.2353  D_B_loss: -0.8972 adv_loss: 0.0211  recon_loss: 0.0434 encoding_loss: 0.0017 G_loss: 0.0661\n",
      "[4800/20000] D_A_loss: -1.2216  D_B_loss: -1.1180 adv_loss: 0.0225  recon_loss: 0.0453 encoding_loss: 0.0010 G_loss: 0.0689\n",
      "[4900/20000] D_A_loss: -1.0910  D_B_loss: -1.0297 adv_loss: 0.0199  recon_loss: 0.0463 encoding_loss: 0.0013 G_loss: 0.0676\n",
      "[5000/20000] D_A_loss: -1.4164  D_B_loss: -1.5417 adv_loss: -0.0003  recon_loss: 0.0450 encoding_loss: 0.0014 G_loss: 0.0461\n",
      "[5100/20000] D_A_loss: -1.2386  D_B_loss: -1.1038 adv_loss: 0.0151  recon_loss: 0.0472 encoding_loss: 0.0011 G_loss: 0.0633\n",
      "[5200/20000] D_A_loss: -1.4326  D_B_loss: -1.2317 adv_loss: 0.0113  recon_loss: 0.0444 encoding_loss: 0.0020 G_loss: 0.0577\n",
      "[5300/20000] D_A_loss: -1.2391  D_B_loss: -1.1125 adv_loss: -0.0009  recon_loss: 0.0447 encoding_loss: 0.0016 G_loss: 0.0454\n",
      "[5400/20000] D_A_loss: -1.2606  D_B_loss: -1.1782 adv_loss: 0.0086  recon_loss: 0.0473 encoding_loss: 0.0017 G_loss: 0.0575\n",
      "[5500/20000] D_A_loss: -1.1658  D_B_loss: -1.2235 adv_loss: 0.0104  recon_loss: 0.0448 encoding_loss: 0.0011 G_loss: 0.0563\n",
      "[5600/20000] D_A_loss: -1.3939  D_B_loss: -1.2531 adv_loss: 0.0115  recon_loss: 0.0458 encoding_loss: 0.0013 G_loss: 0.0586\n",
      "[5700/20000] D_A_loss: -1.3486  D_B_loss: -1.0591 adv_loss: 0.0119  recon_loss: 0.0445 encoding_loss: 0.0013 G_loss: 0.0577\n",
      "[5800/20000] D_A_loss: -1.2178  D_B_loss: -1.0479 adv_loss: 0.0159  recon_loss: 0.0455 encoding_loss: 0.0016 G_loss: 0.0629\n",
      "[5900/20000] D_A_loss: -1.3021  D_B_loss: -1.2119 adv_loss: 0.0085  recon_loss: 0.0440 encoding_loss: 0.0012 G_loss: 0.0537\n",
      "[6000/20000] D_A_loss: -1.1963  D_B_loss: -1.1583 adv_loss: 0.0170  recon_loss: 0.0468 encoding_loss: 0.0015 G_loss: 0.0654\n",
      "[6100/20000] D_A_loss: -1.3448  D_B_loss: -1.1369 adv_loss: 0.0163  recon_loss: 0.0455 encoding_loss: 0.0015 G_loss: 0.0632\n",
      "[6200/20000] D_A_loss: -1.1736  D_B_loss: -1.2585 adv_loss: 0.0404  recon_loss: 0.0411 encoding_loss: 0.0011 G_loss: 0.0826\n",
      "[6300/20000] D_A_loss: -1.2566  D_B_loss: -0.8922 adv_loss: 0.0212  recon_loss: 0.0457 encoding_loss: 0.0024 G_loss: 0.0693\n",
      "[6400/20000] D_A_loss: -1.1333  D_B_loss: -1.0108 adv_loss: 0.0173  recon_loss: 0.0459 encoding_loss: 0.0019 G_loss: 0.0651\n",
      "[6500/20000] D_A_loss: -1.3337  D_B_loss: -1.2765 adv_loss: 0.0134  recon_loss: 0.0453 encoding_loss: 0.0015 G_loss: 0.0602\n",
      "[6600/20000] D_A_loss: -1.3450  D_B_loss: -1.2696 adv_loss: 0.0404  recon_loss: 0.0462 encoding_loss: 0.0030 G_loss: 0.0896\n",
      "[6700/20000] D_A_loss: -1.4305  D_B_loss: -1.3466 adv_loss: 0.0251  recon_loss: 0.0472 encoding_loss: 0.0017 G_loss: 0.0741\n",
      "[6800/20000] D_A_loss: -1.2444  D_B_loss: -1.0976 adv_loss: 0.0089  recon_loss: 0.0456 encoding_loss: 0.0017 G_loss: 0.0562\n",
      "[6900/20000] D_A_loss: -1.2674  D_B_loss: -1.2618 adv_loss: -0.0055  recon_loss: 0.0431 encoding_loss: 0.0020 G_loss: 0.0396\n",
      "[7000/20000] D_A_loss: -1.2472  D_B_loss: -0.9955 adv_loss: -0.0054  recon_loss: 0.0493 encoding_loss: 0.0022 G_loss: 0.0460\n",
      "[7100/20000] D_A_loss: -1.1773  D_B_loss: -1.2072 adv_loss: -0.0057  recon_loss: 0.0470 encoding_loss: 0.0016 G_loss: 0.0429\n",
      "[7200/20000] D_A_loss: -1.1513  D_B_loss: -1.1071 adv_loss: -0.0150  recon_loss: 0.0448 encoding_loss: 0.0022 G_loss: 0.0320\n",
      "[7300/20000] D_A_loss: -1.1559  D_B_loss: -1.2832 adv_loss: -0.0183  recon_loss: 0.0459 encoding_loss: 0.0013 G_loss: 0.0289\n",
      "[7400/20000] D_A_loss: -1.3658  D_B_loss: -1.3323 adv_loss: -0.0144  recon_loss: 0.0436 encoding_loss: 0.0017 G_loss: 0.0309\n",
      "[7500/20000] D_A_loss: -1.2793  D_B_loss: -1.1291 adv_loss: -0.0190  recon_loss: 0.0456 encoding_loss: 0.0014 G_loss: 0.0279\n",
      "[7600/20000] D_A_loss: -1.2498  D_B_loss: -1.1418 adv_loss: -0.0181  recon_loss: 0.0440 encoding_loss: 0.0015 G_loss: 0.0274\n",
      "[7700/20000] D_A_loss: -1.4183  D_B_loss: -1.4236 adv_loss: -0.0047  recon_loss: 0.0445 encoding_loss: 0.0016 G_loss: 0.0413\n",
      "[7800/20000] D_A_loss: -1.2859  D_B_loss: -0.9355 adv_loss: 0.0018  recon_loss: 0.0440 encoding_loss: 0.0015 G_loss: 0.0473\n",
      "[7900/20000] D_A_loss: -1.4084  D_B_loss: -1.0686 adv_loss: 0.0127  recon_loss: 0.0435 encoding_loss: 0.0012 G_loss: 0.0574\n",
      "[8000/20000] D_A_loss: -1.2434  D_B_loss: -1.0472 adv_loss: 0.0237  recon_loss: 0.0440 encoding_loss: 0.0014 G_loss: 0.0691\n",
      "[8100/20000] D_A_loss: -1.1241  D_B_loss: -0.9261 adv_loss: 0.0241  recon_loss: 0.0465 encoding_loss: 0.0023 G_loss: 0.0729\n",
      "[8200/20000] D_A_loss: -1.2582  D_B_loss: -1.2707 adv_loss: 0.0215  recon_loss: 0.0449 encoding_loss: 0.0013 G_loss: 0.0678\n",
      "[8300/20000] D_A_loss: -1.2732  D_B_loss: -1.1434 adv_loss: 0.0283  recon_loss: 0.0454 encoding_loss: 0.0015 G_loss: 0.0752\n",
      "[8400/20000] D_A_loss: -1.2204  D_B_loss: -1.2852 adv_loss: 0.0248  recon_loss: 0.0448 encoding_loss: 0.0018 G_loss: 0.0715\n",
      "[8500/20000] D_A_loss: -1.0918  D_B_loss: -0.9808 adv_loss: 0.0248  recon_loss: 0.0428 encoding_loss: 0.0017 G_loss: 0.0694\n",
      "[8600/20000] D_A_loss: -1.2261  D_B_loss: -1.1431 adv_loss: 0.0233  recon_loss: 0.0449 encoding_loss: 0.0019 G_loss: 0.0700\n",
      "[8700/20000] D_A_loss: -1.2317  D_B_loss: -1.2798 adv_loss: 0.0242  recon_loss: 0.0435 encoding_loss: 0.0014 G_loss: 0.0691\n",
      "[8800/20000] D_A_loss: -1.2574  D_B_loss: -1.0731 adv_loss: 0.0412  recon_loss: 0.0457 encoding_loss: 0.0018 G_loss: 0.0887\n",
      "[8900/20000] D_A_loss: -1.1756  D_B_loss: -1.1916 adv_loss: 0.0351  recon_loss: 0.0471 encoding_loss: 0.0017 G_loss: 0.0839\n",
      "[9000/20000] D_A_loss: -1.3073  D_B_loss: -1.2525 adv_loss: 0.0357  recon_loss: 0.0430 encoding_loss: 0.0012 G_loss: 0.0799\n",
      "[9100/20000] D_A_loss: -1.2033  D_B_loss: -1.1691 adv_loss: 0.0492  recon_loss: 0.0450 encoding_loss: 0.0014 G_loss: 0.0956\n",
      "[9200/20000] D_A_loss: -1.2432  D_B_loss: -0.9871 adv_loss: 0.0445  recon_loss: 0.0452 encoding_loss: 0.0024 G_loss: 0.0922\n",
      "[9300/20000] D_A_loss: -1.3237  D_B_loss: -1.1007 adv_loss: 0.0428  recon_loss: 0.0445 encoding_loss: 0.0018 G_loss: 0.0891\n",
      "[9400/20000] D_A_loss: -1.1268  D_B_loss: -0.9168 adv_loss: 0.0425  recon_loss: 0.0416 encoding_loss: 0.0014 G_loss: 0.0854\n",
      "[9500/20000] D_A_loss: -1.2861  D_B_loss: -1.2470 adv_loss: 0.0364  recon_loss: 0.0421 encoding_loss: 0.0017 G_loss: 0.0802\n",
      "[9600/20000] D_A_loss: -1.2206  D_B_loss: -1.0806 adv_loss: 0.0440  recon_loss: 0.0431 encoding_loss: 0.0011 G_loss: 0.0882\n",
      "[9700/20000] D_A_loss: -1.1880  D_B_loss: -0.9025 adv_loss: 0.0343  recon_loss: 0.0451 encoding_loss: 0.0014 G_loss: 0.0807\n",
      "[9800/20000] D_A_loss: -1.2521  D_B_loss: -1.0173 adv_loss: 0.0402  recon_loss: 0.0420 encoding_loss: 0.0016 G_loss: 0.0839\n",
      "[9900/20000] D_A_loss: -1.1660  D_B_loss: -0.9326 adv_loss: 0.0422  recon_loss: 0.0459 encoding_loss: 0.0017 G_loss: 0.0898\n",
      "[10000/20000] D_A_loss: -1.3217  D_B_loss: -1.0587 adv_loss: 0.0430  recon_loss: 0.0469 encoding_loss: 0.0015 G_loss: 0.0914\n",
      "[10100/20000] D_A_loss: -1.2340  D_B_loss: -1.2107 adv_loss: 0.0580  recon_loss: 0.0482 encoding_loss: 0.0014 G_loss: 0.1075\n",
      "[10200/20000] D_A_loss: -1.2579  D_B_loss: -1.0368 adv_loss: 0.0502  recon_loss: 0.0422 encoding_loss: 0.0015 G_loss: 0.0939\n",
      "[10300/20000] D_A_loss: -1.1515  D_B_loss: -1.1319 adv_loss: 0.0471  recon_loss: 0.0425 encoding_loss: 0.0015 G_loss: 0.0911\n",
      "[10400/20000] D_A_loss: -1.2052  D_B_loss: -1.2638 adv_loss: 0.0563  recon_loss: 0.0466 encoding_loss: 0.0018 G_loss: 0.1046\n",
      "[10500/20000] D_A_loss: -1.2040  D_B_loss: -1.1656 adv_loss: 0.0609  recon_loss: 0.0423 encoding_loss: 0.0022 G_loss: 0.1053\n",
      "[10600/20000] D_A_loss: -1.2002  D_B_loss: -1.0732 adv_loss: 0.0749  recon_loss: 0.0430 encoding_loss: 0.0019 G_loss: 0.1198\n",
      "[10700/20000] D_A_loss: -1.1453  D_B_loss: -1.0758 adv_loss: 0.0712  recon_loss: 0.0452 encoding_loss: 0.0016 G_loss: 0.1180\n",
      "[10800/20000] D_A_loss: -1.3606  D_B_loss: -1.3702 adv_loss: 0.0641  recon_loss: 0.0454 encoding_loss: 0.0015 G_loss: 0.1110\n",
      "[10900/20000] D_A_loss: -1.1088  D_B_loss: -0.9311 adv_loss: 0.0638  recon_loss: 0.0441 encoding_loss: 0.0013 G_loss: 0.1091\n",
      "[11000/20000] D_A_loss: -1.2025  D_B_loss: -1.0626 adv_loss: 0.0690  recon_loss: 0.0466 encoding_loss: 0.0020 G_loss: 0.1176\n",
      "[11100/20000] D_A_loss: -1.2243  D_B_loss: -1.1866 adv_loss: 0.0605  recon_loss: 0.0435 encoding_loss: 0.0016 G_loss: 0.1056\n",
      "[11200/20000] D_A_loss: -1.2273  D_B_loss: -1.2042 adv_loss: 0.0701  recon_loss: 0.0423 encoding_loss: 0.0023 G_loss: 0.1147\n",
      "[11300/20000] D_A_loss: -1.2641  D_B_loss: -1.0779 adv_loss: 0.0726  recon_loss: 0.0448 encoding_loss: 0.0014 G_loss: 0.1188\n",
      "[11400/20000] D_A_loss: -1.1712  D_B_loss: -1.1212 adv_loss: 0.0685  recon_loss: 0.0443 encoding_loss: 0.0015 G_loss: 0.1143\n",
      "[11500/20000] D_A_loss: -1.2160  D_B_loss: -1.2095 adv_loss: 0.0781  recon_loss: 0.0453 encoding_loss: 0.0020 G_loss: 0.1254\n",
      "[11600/20000] D_A_loss: -1.3675  D_B_loss: -1.4752 adv_loss: 0.0901  recon_loss: 0.0453 encoding_loss: 0.0016 G_loss: 0.1370\n",
      "[11700/20000] D_A_loss: -1.3610  D_B_loss: -1.1371 adv_loss: 0.0809  recon_loss: 0.0440 encoding_loss: 0.0016 G_loss: 0.1265\n",
      "[11800/20000] D_A_loss: -1.1864  D_B_loss: -1.1103 adv_loss: 0.0819  recon_loss: 0.0462 encoding_loss: 0.0015 G_loss: 0.1296\n",
      "[11900/20000] D_A_loss: -1.2819  D_B_loss: -1.3197 adv_loss: 0.0818  recon_loss: 0.0451 encoding_loss: 0.0017 G_loss: 0.1286\n",
      "[12000/20000] D_A_loss: -1.2557  D_B_loss: -1.1289 adv_loss: 0.0853  recon_loss: 0.0434 encoding_loss: 0.0015 G_loss: 0.1303\n",
      "[12100/20000] D_A_loss: -1.2609  D_B_loss: -1.1525 adv_loss: 0.0872  recon_loss: 0.0442 encoding_loss: 0.0014 G_loss: 0.1328\n",
      "[12200/20000] D_A_loss: -1.1569  D_B_loss: -1.0405 adv_loss: 0.0931  recon_loss: 0.0417 encoding_loss: 0.0019 G_loss: 0.1367\n",
      "[12300/20000] D_A_loss: -1.2951  D_B_loss: -1.1998 adv_loss: 0.0934  recon_loss: 0.0428 encoding_loss: 0.0018 G_loss: 0.1380\n",
      "[12400/20000] D_A_loss: -1.2921  D_B_loss: -1.1574 adv_loss: 0.0877  recon_loss: 0.0437 encoding_loss: 0.0018 G_loss: 0.1332\n",
      "[12500/20000] D_A_loss: -1.2720  D_B_loss: -1.0805 adv_loss: 0.0886  recon_loss: 0.0440 encoding_loss: 0.0023 G_loss: 0.1348\n",
      "[12600/20000] D_A_loss: -1.3718  D_B_loss: -1.1838 adv_loss: 0.0897  recon_loss: 0.0445 encoding_loss: 0.0017 G_loss: 0.1360\n",
      "[12700/20000] D_A_loss: -1.5019  D_B_loss: -1.2363 adv_loss: 0.0930  recon_loss: 0.0457 encoding_loss: 0.0019 G_loss: 0.1407\n",
      "[12800/20000] D_A_loss: -1.3886  D_B_loss: -1.0783 adv_loss: 0.0890  recon_loss: 0.0445 encoding_loss: 0.0021 G_loss: 0.1355\n",
      "[12900/20000] D_A_loss: -1.1865  D_B_loss: -1.1409 adv_loss: 0.0902  recon_loss: 0.0469 encoding_loss: 0.0016 G_loss: 0.1387\n",
      "[13000/20000] D_A_loss: -1.2731  D_B_loss: -1.0406 adv_loss: 0.0865  recon_loss: 0.0464 encoding_loss: 0.0017 G_loss: 0.1347\n",
      "[13100/20000] D_A_loss: -1.4198  D_B_loss: -1.4438 adv_loss: 0.0841  recon_loss: 0.0455 encoding_loss: 0.0030 G_loss: 0.1325\n",
      "[13200/20000] D_A_loss: -1.3790  D_B_loss: -1.2478 adv_loss: 0.0894  recon_loss: 0.0442 encoding_loss: 0.0021 G_loss: 0.1357\n",
      "[13300/20000] D_A_loss: -1.5167  D_B_loss: -1.2114 adv_loss: 0.0850  recon_loss: 0.0456 encoding_loss: 0.0016 G_loss: 0.1322\n",
      "[13400/20000] D_A_loss: -1.3548  D_B_loss: -0.9591 adv_loss: 0.0919  recon_loss: 0.0430 encoding_loss: 0.0016 G_loss: 0.1365\n",
      "[13500/20000] D_A_loss: -1.3478  D_B_loss: -1.1420 adv_loss: 0.0865  recon_loss: 0.0433 encoding_loss: 0.0015 G_loss: 0.1313\n",
      "[13600/20000] D_A_loss: -1.4182  D_B_loss: -1.1361 adv_loss: 0.0911  recon_loss: 0.0444 encoding_loss: 0.0020 G_loss: 0.1374\n",
      "[13700/20000] D_A_loss: -1.4287  D_B_loss: -1.2935 adv_loss: 0.0859  recon_loss: 0.0432 encoding_loss: 0.0017 G_loss: 0.1308\n",
      "[13800/20000] D_A_loss: -1.2441  D_B_loss: -0.9631 adv_loss: 0.0903  recon_loss: 0.0449 encoding_loss: 0.0014 G_loss: 0.1366\n",
      "[13900/20000] D_A_loss: -1.3938  D_B_loss: -1.1982 adv_loss: 0.0921  recon_loss: 0.0426 encoding_loss: 0.0020 G_loss: 0.1367\n",
      "[14000/20000] D_A_loss: -1.4171  D_B_loss: -1.4816 adv_loss: 0.0945  recon_loss: 0.0441 encoding_loss: 0.0023 G_loss: 0.1410\n",
      "[14100/20000] D_A_loss: -1.5622  D_B_loss: -1.2648 adv_loss: 0.1022  recon_loss: 0.0451 encoding_loss: 0.0017 G_loss: 0.1491\n",
      "[14200/20000] D_A_loss: -1.4429  D_B_loss: -1.2266 adv_loss: 0.0903  recon_loss: 0.0423 encoding_loss: 0.0013 G_loss: 0.1339\n",
      "[14300/20000] D_A_loss: -1.4867  D_B_loss: -1.1178 adv_loss: 0.0951  recon_loss: 0.0446 encoding_loss: 0.0017 G_loss: 0.1414\n",
      "[14400/20000] D_A_loss: -1.4669  D_B_loss: -1.3367 adv_loss: 0.1007  recon_loss: 0.0466 encoding_loss: 0.0017 G_loss: 0.1489\n",
      "[14500/20000] D_A_loss: -1.4392  D_B_loss: -1.3571 adv_loss: 0.0957  recon_loss: 0.0423 encoding_loss: 0.0013 G_loss: 0.1393\n",
      "[14600/20000] D_A_loss: -1.3422  D_B_loss: -1.1083 adv_loss: 0.0994  recon_loss: 0.0467 encoding_loss: 0.0020 G_loss: 0.1481\n",
      "[14700/20000] D_A_loss: -1.4617  D_B_loss: -1.1629 adv_loss: 0.0972  recon_loss: 0.0432 encoding_loss: 0.0014 G_loss: 0.1418\n",
      "[14800/20000] D_A_loss: -1.3464  D_B_loss: -1.1066 adv_loss: 0.1104  recon_loss: 0.0465 encoding_loss: 0.0014 G_loss: 0.1584\n",
      "[14900/20000] D_A_loss: -1.3894  D_B_loss: -1.1311 adv_loss: 0.1052  recon_loss: 0.0419 encoding_loss: 0.0021 G_loss: 0.1492\n",
      "[15000/20000] D_A_loss: -1.5443  D_B_loss: -1.1680 adv_loss: 0.1042  recon_loss: 0.0424 encoding_loss: 0.0015 G_loss: 0.1480\n",
      "[15100/20000] D_A_loss: -1.3505  D_B_loss: -1.1322 adv_loss: 0.1041  recon_loss: 0.0440 encoding_loss: 0.0013 G_loss: 0.1494\n",
      "[15200/20000] D_A_loss: -1.4808  D_B_loss: -1.2567 adv_loss: 0.1058  recon_loss: 0.0458 encoding_loss: 0.0023 G_loss: 0.1539\n",
      "[15300/20000] D_A_loss: -1.4535  D_B_loss: -1.2698 adv_loss: 0.1045  recon_loss: 0.0417 encoding_loss: 0.0014 G_loss: 0.1475\n",
      "[15400/20000] D_A_loss: -1.5099  D_B_loss: -1.3395 adv_loss: 0.1069  recon_loss: 0.0459 encoding_loss: 0.0014 G_loss: 0.1543\n",
      "[15500/20000] D_A_loss: -1.4228  D_B_loss: -1.0186 adv_loss: 0.1103  recon_loss: 0.0427 encoding_loss: 0.0014 G_loss: 0.1545\n",
      "[15600/20000] D_A_loss: -1.3578  D_B_loss: -1.2548 adv_loss: 0.1139  recon_loss: 0.0429 encoding_loss: 0.0015 G_loss: 0.1583\n",
      "[15700/20000] D_A_loss: -1.2798  D_B_loss: -0.9814 adv_loss: 0.1129  recon_loss: 0.0445 encoding_loss: 0.0019 G_loss: 0.1594\n",
      "[15800/20000] D_A_loss: -1.3617  D_B_loss: -1.0707 adv_loss: 0.1187  recon_loss: 0.0452 encoding_loss: 0.0017 G_loss: 0.1657\n",
      "[15900/20000] D_A_loss: -1.4293  D_B_loss: -0.9254 adv_loss: 0.1156  recon_loss: 0.0421 encoding_loss: 0.0016 G_loss: 0.1593\n",
      "[16000/20000] D_A_loss: -1.4972  D_B_loss: -1.0734 adv_loss: 0.1186  recon_loss: 0.0467 encoding_loss: 0.0016 G_loss: 0.1670\n",
      "[16100/20000] D_A_loss: -1.4091  D_B_loss: -1.1407 adv_loss: 0.1156  recon_loss: 0.0429 encoding_loss: 0.0015 G_loss: 0.1600\n",
      "[16200/20000] D_A_loss: -1.4235  D_B_loss: -1.1741 adv_loss: 0.1136  recon_loss: 0.0414 encoding_loss: 0.0016 G_loss: 0.1566\n",
      "[16300/20000] D_A_loss: -1.3873  D_B_loss: -1.0890 adv_loss: 0.1189  recon_loss: 0.0422 encoding_loss: 0.0019 G_loss: 0.1630\n",
      "[16400/20000] D_A_loss: -1.4385  D_B_loss: -1.1707 adv_loss: 0.1151  recon_loss: 0.0429 encoding_loss: 0.0018 G_loss: 0.1599\n",
      "[16500/20000] D_A_loss: -1.4877  D_B_loss: -0.9857 adv_loss: 0.1130  recon_loss: 0.0428 encoding_loss: 0.0014 G_loss: 0.1572\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 43\u001b[0m\n\u001b[1;32m     39\u001b[0m opt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout_sample_prediction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m opt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDendritic\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 43\u001b[0m \u001b[43mtrain_scPreGAN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/g/kreshuk/katzalis/repos/thesis/lib/scPreGAN/scPreGAN/reproducibility/scPreGAN_OOD_prediction.py:277\u001b[0m, in \u001b[0;36mtrain_scPreGAN\u001b[0;34m(config, opt)\u001b[0m\n\u001b[1;32m    274\u001b[0m out_BA \u001b[38;5;241m=\u001b[39m D_A(BA\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[1;32m    275\u001b[0m out_AB \u001b[38;5;241m=\u001b[39m D_B(AB\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[0;32m--> 277\u001b[0m D_A_gradient_penalty \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_gradient_penalty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_A\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mlambta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlambta_gp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_wgan_div\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muse_wgan_div\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m D_B_gradient_penalty \u001b[38;5;241m=\u001b[39m calc_gradient_penalty(D_B, real_B\u001b[38;5;241m.\u001b[39mdetach(), AB\u001b[38;5;241m.\u001b[39mdetach(),\n\u001b[1;32m    281\u001b[0m                                              batch_size\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m], use_cuda\u001b[38;5;241m=\u001b[39mopt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    282\u001b[0m                                              lambta\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambta_gp\u001b[39m\u001b[38;5;124m'\u001b[39m], use_wgan_div\u001b[38;5;241m=\u001b[39mopt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_wgan_div\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgan_loss\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvanilla\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/g/kreshuk/katzalis/repos/thesis/lib/scPreGAN/scPreGAN/reproducibility/scPreGAN_OOD_prediction.py:80\u001b[0m, in \u001b[0;36mcalc_gradient_penalty\u001b[0;34m(netD, real_data, fake_data, batch_size, use_cuda, lambta, use_wgan_div, k, p)\u001b[0m\n\u001b[1;32m     77\u001b[0m     interpolates \u001b[38;5;241m=\u001b[39m interpolates\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     78\u001b[0m interpolates \u001b[38;5;241m=\u001b[39m Variable(interpolates, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 80\u001b[0m disc_interpolates \u001b[38;5;241m=\u001b[39m \u001b[43mnetD\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterpolates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m gradients \u001b[38;5;241m=\u001b[39m autograd\u001b[38;5;241m.\u001b[39mgrad(outputs\u001b[38;5;241m=\u001b[39mdisc_interpolates, inputs\u001b[38;5;241m=\u001b[39minterpolates,\n\u001b[1;32m     83\u001b[0m                           grad_outputs\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones(disc_interpolates\u001b[38;5;241m.\u001b[39msize())\u001b[38;5;241m.\u001b[39mcuda() \u001b[38;5;28;01mif\u001b[39;00m use_cuda \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mones(\n\u001b[1;32m     84\u001b[0m                               disc_interpolates\u001b[38;5;241m.\u001b[39msize()),\n\u001b[1;32m     85\u001b[0m                           create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, only_inputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_wgan_div:\n",
      "File \u001b[0;32m/g/kreshuk/katzalis/conda/miniforge3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/g/kreshuk/katzalis/conda/miniforge3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/g/kreshuk/katzalis/repos/thesis/lib/scPreGAN/scPreGAN/reproducibility/model/Discriminator.py:16\u001b[0m, in \u001b[0;36mDiscriminator.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 16\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(out)\n\u001b[1;32m     18\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout(out)\n",
      "File \u001b[0;32m/g/kreshuk/katzalis/conda/miniforge3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/g/kreshuk/katzalis/conda/miniforge3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/g/kreshuk/katzalis/conda/miniforge3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/g/kreshuk/katzalis/conda/miniforge3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/g/kreshuk/katzalis/conda/miniforge3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:1592\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1587\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1588\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward pre-hook must return None or a tuple \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1589\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs_kwargs_result\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1590\u001b[0m             )\n\u001b[1;32m   1591\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1592\u001b[0m     args_result \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1593\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1594\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args_result, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[0;32m/g/kreshuk/katzalis/conda/miniforge3/envs/thesis/lib/python3.10/site-packages/torch/nn/utils/spectral_norm.py:106\u001b[0m, in \u001b[0;36mSpectralNorm.__call__\u001b[0;34m(self, module, inputs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, module: Module, inputs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 106\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(module, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_power_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/g/kreshuk/katzalis/conda/miniforge3/envs/thesis/lib/python3.10/site-packages/torch/nn/utils/spectral_norm.py:86\u001b[0m, in \u001b[0;36mSpectralNorm.compute_weight\u001b[0;34m(self, module, do_power_iteration)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_power_iterations):\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# Spectral norm of weight equals to `u^T W v`, where `u` and `v`\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m# are the first left and right singular vectors.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# This power iteration produces approximations of `u` and `v`.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     v \u001b[38;5;241m=\u001b[39m normalize(torch\u001b[38;5;241m.\u001b[39mmv(weight_mat\u001b[38;5;241m.\u001b[39mt(), u), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps, out\u001b[38;5;241m=\u001b[39mv)\n\u001b[0;32m---> 86\u001b[0m     u \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_power_iterations \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;66;03m# See above on why we need to clone\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     u \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mclone(memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcontiguous_format)\n",
      "File \u001b[0;32m/g/kreshuk/katzalis/conda/miniforge3/envs/thesis/lib/python3.10/site-packages/torch/nn/functional.py:4819\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(input, p, dim, eps, out)\u001b[0m\n\u001b[1;32m   4817\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m/\u001b[39m denom\n\u001b[1;32m   4818\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4819\u001b[0m     denom \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclamp_min_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mexpand_as(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   4820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;28minput\u001b[39m, denom, out\u001b[38;5;241m=\u001b[39mout)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scPreGAN.reproducibility.scPreGAN_OOD_prediction import train_scPreGAN\n",
    "\n",
    "opt = {\n",
    "    'cuda': True,\n",
    "    'dataPath': data_path,\n",
    "    'checkpoint_dir': None,\n",
    "    'condition_key': 'condition',\n",
    "    'condition': {\"case\": \"stimulated\", \"control\": \"control\"},\n",
    "    'cell_type_key': 'cell_type',\n",
    "    'prediction_type': None,\n",
    "    'out_sample_prediction': True,\n",
    "    'manual_seed': 3060,\n",
    "    'data_name': 'pbmc',\n",
    "    'model_name': 'pbmc_OOD',\n",
    "    'outf': pbmc_path,\n",
    "    'validation': False,\n",
    "    'valid_dataPath': None,\n",
    "    'use_sn': True,\n",
    "    'use_wgan_div': True,\n",
    "    'gan_loss': 'wgan'\n",
    "}\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"batch_size\": 64,\n",
    "    \"lambda_adv\": 0.001,\n",
    "    \"lambda_encoding\": 0.1,\n",
    "    \"lambda_l1_reg\": 0,\n",
    "    \"lambda_recon\": 1,\n",
    "    \"lambta_gp\": 1,\n",
    "    \"lr_disc\": 0.001,\n",
    "    \"lr_e\": 0.0001,\n",
    "    \"lr_g\": 0.001,\n",
    "    \"min_hidden_size\": 256,\n",
    "    \"niter\": 20000,\n",
    "    \"z_dim\": 16\n",
    "}\n",
    "\n",
    "opt['out_sample_prediction'] = True\n",
    "opt['prediction_type'] = \"Dendritic\"\n",
    "\n",
    "\n",
    "train_scPreGAN(opt=opt, config=config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
